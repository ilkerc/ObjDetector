{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K40c (CNMeM is enabled with initial size: 33.0% of memory, cuDNN 5105)\n",
      "/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:601: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import matplotlib\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import pylab as P\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle as pickle\n",
    "from DiscreteLayer import DiscreteLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "# theano.config.exception_verbosity = 'high'\n",
    "conv = lasagne.layers.Conv2DLayer\n",
    "pool = lasagne.layers.MaxPool2DLayer\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "DIM = 60\n",
    "NUM_CLASSES = 10\n",
    "mnist_cluttered = \"mnist_cluttered_60x60_6distortions.npz\"\n",
    "#DISC\n",
    "DISC = True\n",
    "MINS = (.3, -.3, -.8, -.3, .5, -0.7)\n",
    "MAXS = (1.1, .1, 1.1, .4, 1.1, 1.5)\n",
    "RANGES = (50, 50, 50, 50, 50, 50)\n",
    "#Test Specs\n",
    "TH_ACC = 0.98\n",
    "NUM_TEST = 10\n",
    "TEST_NAME = 'test1_disc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: (50000, 1, 60, 60)\n",
      "Validation samples: (10000, 1, 60, 60)\n",
      "Test samples: (10000, 1, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    data = np.load(mnist_cluttered)\n",
    "    X_train, y_train = data['x_train'], np.argmax(data['y_train'], axis=-1)\n",
    "    X_valid, y_valid = data['x_valid'], np.argmax(data['y_valid'], axis=-1)\n",
    "    X_test, y_test = data['x_test'], np.argmax(data['y_test'], axis=-1)\n",
    "\n",
    "    # reshape for convolutions\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1, DIM, DIM))\n",
    "    X_valid = X_valid.reshape((X_valid.shape[0], 1, DIM, DIM))\n",
    "    X_test = X_test.reshape((X_test.shape[0], 1, DIM, DIM))\n",
    "    \n",
    "    print \"Train samples:\", X_train.shape\n",
    "    print \"Validation samples:\", X_valid.shape\n",
    "    print \"Test samples:\", X_test.shape\n",
    "\n",
    "    return dict(\n",
    "        X_train=lasagne.utils.floatX(X_train),\n",
    "        y_train=y_train.astype('int32'),\n",
    "        X_valid=lasagne.utils.floatX(X_valid),\n",
    "        y_valid=y_valid.astype('int32'),\n",
    "        X_test=lasagne.utils.floatX(X_test),\n",
    "        y_test=y_test.astype('int32'),\n",
    "        num_examples_train=X_train.shape[0],\n",
    "        num_examples_valid=X_valid.shape[0],\n",
    "        num_examples_test=X_test.shape[0],\n",
    "        input_height=X_train.shape[2],\n",
    "        input_width=X_train.shape[3],\n",
    "        output_dim=10,)\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(input_width, input_height, output_dim, mins, maxs, ranges,\n",
    "                batch_size=BATCH_SIZE, withdisc=True):\n",
    "    ini = lasagne.init.HeUniform()\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, input_width, input_height),)\n",
    "\n",
    "    # Localization network\n",
    "    b = np.zeros((2, 3), dtype=theano.config.floatX)\n",
    "    b[0, 0] = 1\n",
    "    b[1, 1] = 1\n",
    "    b = b.flatten()\n",
    "    loc_l1 = pool(l_in, pool_size=(2, 2))\n",
    "    loc_l2 = conv(\n",
    "        loc_l1, num_filters=20, filter_size=(5, 5), W=ini)\n",
    "    loc_l3 = pool(loc_l2, pool_size=(2, 2))\n",
    "    loc_l4 = conv(loc_l3, num_filters=20, filter_size=(5, 5), W=ini)\n",
    "    loc_l5 = lasagne.layers.DenseLayer(\n",
    "        loc_l4, num_units=50, W=lasagne.init.HeUniform('relu'))\n",
    "    loc_out = lasagne.layers.DenseLayer(\n",
    "        loc_l5, num_units=6, b=b, W=lasagne.init.Constant(0.0), \n",
    "        nonlinearity=lasagne.nonlinearities.identity, name='param_regressor')\n",
    "    \n",
    "    if withdisc:\n",
    "        l_dis = DiscreteLayer(loc_out, mins, maxs, ranges, name='disclayer')\n",
    "        print(\"Using Discret. Layer\")\n",
    "    else:\n",
    "        l_dis = loc_out\n",
    "        print(\"No Disc. Layer\")\n",
    "    \n",
    "    # Transformer network\n",
    "    l_trans1 = lasagne.layers.TransformerLayer(l_in, l_dis, downsample_factor=3.0)\n",
    "    print \"Transformer network output shape: \", l_trans1.output_shape\n",
    "    \n",
    "    # Classification network\n",
    "    class_l1 = conv(\n",
    "        l_trans1,\n",
    "        num_filters=32,\n",
    "        filter_size=(3, 3),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )\n",
    "    class_l2 = pool(class_l1, pool_size=(2, 2))\n",
    "    class_l3 = conv(\n",
    "        class_l2,\n",
    "        num_filters=32,\n",
    "        filter_size=(3, 3),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )\n",
    "    class_l4 = pool(class_l3, pool_size=(2, 2))\n",
    "    class_l5 = lasagne.layers.DenseLayer(\n",
    "        class_l4,\n",
    "        num_units=256,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )\n",
    "\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "        class_l5,\n",
    "        num_units=output_dim,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax,\n",
    "        W=ini,\n",
    "    )\n",
    "\n",
    "    return l_out, l_trans1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(X, y):\n",
    "    # History Keeping\n",
    "    param_output = []\n",
    "    disc_output = []\n",
    "    # History\n",
    "    num_samples = X.shape[0]\n",
    "    num_batches = int(np.ceil(num_samples / float(BATCH_SIZE)))\n",
    "    costs = []\n",
    "    correct = 0\n",
    "    for i in range(num_batches):\n",
    "        idx = range(i*BATCH_SIZE, np.minimum((i+1)*BATCH_SIZE, num_samples))\n",
    "        X_batch = X[idx]\n",
    "        y_batch = y[idx]\n",
    "        if DISC:\n",
    "            cost_batch, output_train, l_disc_output, l_paramreg_output = train(X_batch, y_batch)\n",
    "            param_output = np.append(param_output, l_paramreg_output)\n",
    "            disc_output = np.append(disc_output, l_disc_output)\n",
    "        else:\n",
    "            cost_batch, output_train = train(X_batch, y_batch)\n",
    "        costs += [cost_batch]\n",
    "        preds = np.argmax(output_train, axis=-1)\n",
    "        correct += np.sum(y_batch == preds)\n",
    "        \n",
    "    return np.mean(costs), correct / float(num_samples), param_output, disc_output\n",
    "\n",
    "\n",
    "def eval_epoch(X, y):\n",
    "    output_eval, transform_eval = eval(X)\n",
    "    preds = np.argmax(output_eval, axis=-1)\n",
    "    acc = np.mean(preds == y)\n",
    "    return acc, transform_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new model\n",
      "Using Discret. Layer\n",
      "Transformer network output shape:  (None, 1, 20, 20)\n",
      "Epoch 0: Train cost 1.73408138752, Train acc 0.38262, val acc 0.6471, test acc 0.6512, took 5.94 sec.\n",
      "Epoch 1: Train cost 0.831402242184, Train acc 0.73136, val acc 0.7696, test acc 0.7674, took 5.94 sec.\n",
      "Epoch 2: Train cost 0.586590349674, Train acc 0.8094, val acc 0.8386, test acc 0.8456, took 5.93 sec.\n",
      "Epoch 3: Train cost 0.458930879831, Train acc 0.85184, val acc 0.8719, test acc 0.874, took 5.93 sec.\n",
      "Epoch 4: Train cost 0.378249824047, Train acc 0.8785, val acc 0.8792, test acc 0.8781, took 5.93 sec.\n",
      "Epoch 5: Train cost 0.335703551769, Train acc 0.8916, val acc 0.8682, test acc 0.8693, took 6.03 sec.\n",
      "Epoch 6: Train cost 0.315982013941, Train acc 0.89836, val acc 0.9007, test acc 0.8997, took 6.18 sec.\n",
      "Epoch 7: Train cost 0.267226457596, Train acc 0.91414, val acc 0.912, test acc 0.9121, took 5.99 sec.\n",
      "Epoch 8: Train cost 0.252310276031, Train acc 0.91794, val acc 0.9011, test acc 0.9067, took 6.0 sec.\n",
      "Epoch 9: Train cost 0.229448974133, Train acc 0.92552, val acc 0.9152, test acc 0.9134, took 5.92 sec.\n",
      "Epoch 10: Train cost 0.233549192548, Train acc 0.92426, val acc 0.9131, test acc 0.9093, took 6.15 sec.\n",
      "Epoch 11: Train cost 0.216630160809, Train acc 0.9292, val acc 0.9255, test acc 0.9301, took 6.05 sec.\n",
      "Epoch 12: Train cost 0.193759486079, Train acc 0.93686, val acc 0.9316, test acc 0.9302, took 6.01 sec.\n",
      "Epoch 13: Train cost 0.186588048935, Train acc 0.9397, val acc 0.9352, test acc 0.9402, took 5.99 sec.\n",
      "Epoch 14: Train cost 0.183604478836, Train acc 0.94096, val acc 0.9351, test acc 0.9353, took 5.99 sec.\n",
      "Epoch 15: Train cost 0.166716009378, Train acc 0.94572, val acc 0.9359, test acc 0.9406, took 6.01 sec.\n",
      "Epoch 16: Train cost 0.176031291485, Train acc 0.9426, val acc 0.9377, test acc 0.9401, took 6.01 sec.\n",
      "Epoch 17: Train cost 0.162024974823, Train acc 0.94758, val acc 0.939, test acc 0.9409, took 5.98 sec.\n",
      "Epoch 18: Train cost 0.153169646859, Train acc 0.95108, val acc 0.9451, test acc 0.9452, took 6.01 sec.\n",
      "New LR: 0.000700000033248\n",
      "Epoch 19: Train cost 0.135899528861, Train acc 0.95602, val acc 0.9467, test acc 0.9481, took 6.01 sec.\n",
      "Epoch 20: Train cost 0.118979275227, Train acc 0.96114, val acc 0.9495, test acc 0.9481, took 6.01 sec.\n",
      "Epoch 21: Train cost 0.127352252603, Train acc 0.95744, val acc 0.9483, test acc 0.9498, took 5.99 sec.\n",
      "Epoch 22: Train cost 0.112743504345, Train acc 0.96312, val acc 0.9504, test acc 0.9532, took 5.98 sec.\n",
      "Epoch 23: Train cost 0.112557530403, Train acc 0.96246, val acc 0.9545, test acc 0.9527, took 6.02 sec.\n",
      "Epoch 24: Train cost 0.114494614303, Train acc 0.96192, val acc 0.9506, test acc 0.9504, took 6.01 sec.\n",
      "Epoch 25: Train cost 0.104044526815, Train acc 0.96568, val acc 0.9501, test acc 0.9537, took 5.98 sec.\n",
      "Epoch 26: Train cost 0.101337939501, Train acc 0.967, val acc 0.9569, test acc 0.955, took 5.98 sec.\n",
      "Epoch 27: Train cost 0.100482061505, Train acc 0.96696, val acc 0.9554, test acc 0.9569, took 6.01 sec.\n",
      "Epoch 28: Train cost 0.102412007749, Train acc 0.9662, val acc 0.9447, test acc 0.945, took 6.01 sec.\n",
      "Epoch 29: Train cost 0.0981140360236, Train acc 0.9664, val acc 0.9588, test acc 0.9593, took 5.98 sec.\n",
      "Epoch 30: Train cost 0.096425332129, Train acc 0.96792, val acc 0.9519, test acc 0.9558, took 5.98 sec.\n",
      "Epoch 31: Train cost 0.0883074998856, Train acc 0.97096, val acc 0.9551, test acc 0.9589, took 6.0 sec.\n",
      "Epoch 32: Train cost 0.0845710411668, Train acc 0.97198, val acc 0.9556, test acc 0.9591, took 6.0 sec.\n",
      "Epoch 33: Train cost 0.0896350741386, Train acc 0.96988, val acc 0.9547, test acc 0.957, took 5.98 sec.\n",
      "Epoch 34: Train cost 0.0843171030283, Train acc 0.9713, val acc 0.9542, test acc 0.958, took 5.98 sec.\n",
      "Epoch 35: Train cost 0.0817551836371, Train acc 0.973, val acc 0.9502, test acc 0.9565, took 6.01 sec.\n",
      "Epoch 36: Train cost 0.0779125466943, Train acc 0.974, val acc 0.9586, test acc 0.9593, took 6.0 sec.\n",
      "Epoch 37: Train cost 0.0877983942628, Train acc 0.9705, val acc 0.9543, test acc 0.9527, took 5.98 sec.\n",
      "Epoch 38: Train cost 0.0834263563156, Train acc 0.97232, val acc 0.9597, test acc 0.9604, took 5.98 sec.\n",
      "New LR: 0.000490000023274\n",
      "Epoch 39: Train cost 0.075476564467, Train acc 0.97568, val acc 0.9585, test acc 0.9617, took 5.99 sec.\n",
      "Epoch 40: Train cost 0.0648569017649, Train acc 0.97842, val acc 0.962, test acc 0.9631, took 5.99 sec.\n",
      "Epoch 41: Train cost 0.0667651295662, Train acc 0.97788, val acc 0.9616, test acc 0.9616, took 5.96 sec.\n",
      "Epoch 42: Train cost 0.0579211264849, Train acc 0.98068, val acc 0.9649, test acc 0.9636, took 5.97 sec.\n",
      "\n",
      "Test 0 is over, saving to history\n",
      "\n",
      "Total time spent: 257.8 seconds\n",
      "Traing Acc: 0.98068\n",
      "Test Acc: 0.9636\n",
      "Validation Acc: 0.9649\n",
      "\n",
      "Creating new model\n",
      "Using Discret. Layer\n",
      "Transformer network output shape:  (None, 1, 20, 20)\n",
      "Epoch 0: Train cost 1.79757940769, Train acc 0.35918, val acc 0.5165, test acc 0.5244, took 5.94 sec.\n",
      "Epoch 1: Train cost 0.992807865143, Train acc 0.67344, val acc 0.7549, test acc 0.7589, took 6.15 sec.\n",
      "Epoch 2: Train cost 0.632745921612, Train acc 0.79632, val acc 0.8271, test acc 0.8256, took 6.08 sec.\n",
      "Epoch 3: Train cost 0.497061759233, Train acc 0.84102, val acc 0.8437, test acc 0.8376, took 6.02 sec.\n",
      "Epoch 4: Train cost 0.413319408894, Train acc 0.86738, val acc 0.8607, test acc 0.8648, took 6.0 sec.\n",
      "Epoch 5: Train cost 0.353076428175, Train acc 0.88592, val acc 0.9004, test acc 0.896, took 6.01 sec.\n",
      "Epoch 6: Train cost 0.309098541737, Train acc 0.90166, val acc 0.8859, test acc 0.8876, took 6.03 sec.\n",
      "Epoch 7: Train cost 0.286431998014, Train acc 0.90786, val acc 0.9232, test acc 0.921, took 6.01 sec.\n",
      "Epoch 8: Train cost 0.267228335142, Train acc 0.9134, val acc 0.9099, test acc 0.9057, took 5.99 sec.\n",
      "Epoch 9: Train cost 0.234523192048, Train acc 0.92544, val acc 0.9183, test acc 0.9208, took 6.0 sec.\n",
      "Epoch 10: Train cost 0.224131971598, Train acc 0.92792, val acc 0.9118, test acc 0.9168, took 6.03 sec.\n",
      "Epoch 11: Train cost 0.208510026336, Train acc 0.93332, val acc 0.9315, test acc 0.9297, took 6.01 sec.\n",
      "Epoch 12: Train cost 0.20031312108, Train acc 0.93458, val acc 0.9089, test acc 0.9102, took 5.99 sec.\n",
      "Epoch 13: Train cost 0.189222216606, Train acc 0.93946, val acc 0.9389, test acc 0.9361, took 6.01 sec.\n",
      "Epoch 14: Train cost 0.17671379447, Train acc 0.94326, val acc 0.9394, test acc 0.9347, took 6.02 sec.\n",
      "Epoch 15: Train cost 0.172806560993, Train acc 0.9435, val acc 0.9233, test acc 0.9222, took 6.0 sec.\n",
      "Epoch 16: Train cost 0.170119404793, Train acc 0.9453, val acc 0.942, test acc 0.9416, took 5.99 sec.\n",
      "Epoch 17: Train cost 0.153343498707, Train acc 0.95004, val acc 0.9173, test acc 0.9201, took 6.0 sec.\n",
      "Epoch 18: Train cost 0.161846280098, Train acc 0.94802, val acc 0.9446, test acc 0.9455, took 6.01 sec.\n",
      "New LR: 0.000700000033248\n",
      "Epoch 19: Train cost 0.156845882535, Train acc 0.94956, val acc 0.9281, test acc 0.9286, took 6.0 sec.\n",
      "Epoch 20: Train cost 0.134403273463, Train acc 0.9569, val acc 0.9533, test acc 0.9539, took 5.99 sec.\n",
      "Epoch 21: Train cost 0.119117327034, Train acc 0.9608, val acc 0.9554, test acc 0.9576, took 6.0 sec.\n",
      "Epoch 22: Train cost 0.119606718421, Train acc 0.9601, val acc 0.951, test acc 0.9526, took 6.02 sec.\n",
      "Epoch 23: Train cost 0.117074079812, Train acc 0.96074, val acc 0.9554, test acc 0.9544, took 6.01 sec.\n",
      "Epoch 24: Train cost 0.121109679341, Train acc 0.96002, val acc 0.9532, test acc 0.9526, took 5.99 sec.\n",
      "Epoch 25: Train cost 0.112994171679, Train acc 0.96226, val acc 0.9555, test acc 0.9553, took 6.01 sec.\n",
      "Epoch 26: Train cost 0.106521353126, Train acc 0.96514, val acc 0.9546, test acc 0.9523, took 6.02 sec.\n",
      "Epoch 27: Train cost 0.110423743725, Train acc 0.96382, val acc 0.9519, test acc 0.956, took 6.0 sec.\n",
      "Epoch 28: Train cost 0.102707788348, Train acc 0.96674, val acc 0.9589, test acc 0.9555, took 5.98 sec.\n",
      "Epoch 29: Train cost 0.101553589106, Train acc 0.96638, val acc 0.9472, test acc 0.9466, took 6.0 sec.\n",
      "Epoch 30: Train cost 0.100328214467, Train acc 0.96658, val acc 0.9498, test acc 0.9532, took 6.01 sec.\n",
      "Epoch 31: Train cost 0.0912134200335, Train acc 0.96936, val acc 0.9523, test acc 0.9516, took 6.0 sec.\n",
      "Epoch 32: Train cost 0.0928098708391, Train acc 0.96892, val acc 0.95, test acc 0.9528, took 5.99 sec.\n",
      "Epoch 33: Train cost 0.0840452089906, Train acc 0.97208, val acc 0.9572, test acc 0.9581, took 6.0 sec.\n",
      "Epoch 34: Train cost 0.0842488929629, Train acc 0.97134, val acc 0.9531, test acc 0.9563, took 6.01 sec.\n",
      "Epoch 35: Train cost 0.0875544250011, Train acc 0.9702, val acc 0.9515, test acc 0.9522, took 6.0 sec.\n",
      "Epoch 36: Train cost 0.0857209861279, Train acc 0.97268, val acc 0.9519, test acc 0.955, took 5.99 sec.\n",
      "Epoch 37: Train cost 0.0872723460197, Train acc 0.97146, val acc 0.9519, test acc 0.952, took 6.0 sec.\n",
      "Epoch 38: Train cost 0.0830251425505, Train acc 0.97146, val acc 0.9486, test acc 0.9519, took 6.01 sec.\n",
      "New LR: 0.000490000023274\n",
      "Epoch 39: Train cost 0.0777358785272, Train acc 0.9749, val acc 0.9613, test acc 0.961, took 6.0 sec.\n",
      "Epoch 40: Train cost 0.0649245306849, Train acc 0.97842, val acc 0.9582, test acc 0.9569, took 5.98 sec.\n",
      "Epoch 41: Train cost 0.0669055730104, Train acc 0.97862, val acc 0.9607, test acc 0.9609, took 6.0 sec.\n",
      "Epoch 42: Train cost 0.0608508139849, Train acc 0.97934, val acc 0.9624, test acc 0.963, took 6.15 sec.\n",
      "Epoch 43: Train cost 0.0549369752407, Train acc 0.9823, val acc 0.9618, test acc 0.9612, took 6.21 sec.\n",
      "\n",
      "Test 1 is over, saving to history\n",
      "\n",
      "Total time spent: 264.67 seconds\n",
      "Traing Acc: 0.9823\n",
      "Test Acc: 0.9612\n",
      "Validation Acc: 0.9618\n",
      "\n",
      "Creating new model\n",
      "Using Discret. Layer\n",
      "Transformer network output shape:  (None, 1, 20, 20)\n",
      "Epoch 0: Train cost 1.79773068428, Train acc 0.35672, val acc 0.5886, test acc 0.5863, took 5.92 sec.\n",
      "Epoch 1: Train cost 0.840245246887, Train acc 0.72332, val acc 0.7873, test acc 0.7905, took 6.12 sec.\n",
      "Epoch 2: Train cost 0.572529911995, Train acc 0.8161, val acc 0.8413, test acc 0.844, took 6.09 sec.\n",
      "Epoch 3: Train cost 0.449666470289, Train acc 0.85604, val acc 0.8763, test acc 0.8799, took 6.0 sec.\n",
      "Epoch 4: Train cost 0.37844568491, Train acc 0.8789, val acc 0.8844, test acc 0.8817, took 5.98 sec.\n",
      "Epoch 5: Train cost 0.333129376173, Train acc 0.89288, val acc 0.8951, test acc 0.8993, took 6.0 sec.\n",
      "Epoch 6: Train cost 0.297437697649, Train acc 0.90342, val acc 0.9029, test acc 0.9064, took 6.01 sec.\n",
      "Epoch 7: Train cost 0.256826490164, Train acc 0.91758, val acc 0.9064, test acc 0.9082, took 5.99 sec.\n",
      "Epoch 8: Train cost 0.240322887897, Train acc 0.92284, val acc 0.9089, test acc 0.9142, took 5.99 sec.\n",
      "Epoch 9: Train cost 0.224748462439, Train acc 0.92834, val acc 0.9303, test acc 0.9313, took 6.0 sec.\n",
      "Epoch 10: Train cost 0.2044531703, Train acc 0.93306, val acc 0.9243, test acc 0.9278, took 6.01 sec.\n",
      "Epoch 11: Train cost 0.196890339255, Train acc 0.93564, val acc 0.9214, test acc 0.9244, took 6.0 sec.\n",
      "Epoch 12: Train cost 0.18471865356, Train acc 0.93982, val acc 0.9239, test acc 0.9277, took 5.98 sec.\n",
      "Epoch 13: Train cost 0.169786691666, Train acc 0.94568, val acc 0.9378, test acc 0.9383, took 5.99 sec.\n",
      "Epoch 14: Train cost 0.157491624355, Train acc 0.94776, val acc 0.9322, test acc 0.9374, took 6.01 sec.\n",
      "Epoch 15: Train cost 0.15675213933, Train acc 0.949, val acc 0.9422, test acc 0.9479, took 5.99 sec.\n",
      "Epoch 16: Train cost 0.153138622642, Train acc 0.94898, val acc 0.9451, test acc 0.9419, took 5.97 sec.\n",
      "Epoch 17: Train cost 0.144198969007, Train acc 0.95266, val acc 0.9469, test acc 0.9521, took 6.0 sec.\n",
      "Epoch 18: Train cost 0.133899927139, Train acc 0.95634, val acc 0.9434, test acc 0.9395, took 6.0 sec.\n",
      "New LR: 0.000700000033248\n",
      "Epoch 19: Train cost 0.135493665934, Train acc 0.95522, val acc 0.9468, test acc 0.9532, took 5.99 sec.\n",
      "Epoch 20: Train cost 0.117604792118, Train acc 0.96134, val acc 0.9504, test acc 0.9524, took 5.97 sec.\n",
      "Epoch 21: Train cost 0.109256371856, Train acc 0.964, val acc 0.9529, test acc 0.9554, took 5.99 sec.\n",
      "Epoch 22: Train cost 0.105425037444, Train acc 0.9661, val acc 0.952, test acc 0.9516, took 6.01 sec.\n",
      "Epoch 23: Train cost 0.104763381183, Train acc 0.96584, val acc 0.9488, test acc 0.9482, took 5.99 sec.\n",
      "Epoch 24: Train cost 0.0968466177583, Train acc 0.96818, val acc 0.9537, test acc 0.9571, took 5.95 sec.\n",
      "Epoch 25: Train cost 0.0924065038562, Train acc 0.96926, val acc 0.9554, test acc 0.9591, took 5.91 sec.\n",
      "Epoch 26: Train cost 0.099298350513, Train acc 0.96764, val acc 0.9505, test acc 0.9524, took 6.19 sec.\n",
      "Epoch 27: Train cost 0.097739726305, Train acc 0.9675, val acc 0.9543, test acc 0.9565, took 5.99 sec.\n",
      "Epoch 28: Train cost 0.0945820212364, Train acc 0.96792, val acc 0.958, test acc 0.9546, took 6.01 sec.\n",
      "Epoch 29: Train cost 0.0845302641392, Train acc 0.97146, val acc 0.9544, test acc 0.9578, took 5.98 sec.\n",
      "Epoch 30: Train cost 0.0844574570656, Train acc 0.97186, val acc 0.9562, test acc 0.959, took 5.96 sec.\n",
      "Epoch 31: Train cost 0.0844307467341, Train acc 0.97112, val acc 0.9526, test acc 0.9535, took 5.99 sec.\n",
      "Epoch 32: Train cost 0.0841621309519, Train acc 0.97236, val acc 0.956, test acc 0.9554, took 6.01 sec.\n",
      "Epoch 33: Train cost 0.0784530714154, Train acc 0.9742, val acc 0.9531, test acc 0.9556, took 5.98 sec.\n",
      "Epoch 34: Train cost 0.0908949896693, Train acc 0.97, val acc 0.9524, test acc 0.9538, took 5.95 sec.\n",
      "Epoch 35: Train cost 0.0761576294899, Train acc 0.97454, val acc 0.9592, test acc 0.9621, took 5.92 sec.\n",
      "Epoch 36: Train cost 0.0707391947508, Train acc 0.9761, val acc 0.9582, test acc 0.959, took 6.19 sec.\n",
      "Epoch 37: Train cost 0.0734109655023, Train acc 0.97538, val acc 0.9567, test acc 0.9572, took 5.99 sec.\n",
      "Epoch 38: Train cost 0.0663913413882, Train acc 0.97798, val acc 0.9599, test acc 0.9585, took 6.01 sec.\n",
      "New LR: 0.000490000023274\n",
      "Epoch 39: Train cost 0.0690590515733, Train acc 0.97588, val acc 0.9548, test acc 0.9531, took 5.98 sec.\n",
      "Epoch 40: Train cost 0.0581409260631, Train acc 0.98124, val acc 0.9628, test acc 0.9618, took 5.95 sec.\n",
      "\n",
      "Test 2 is over, saving to history\n",
      "\n",
      "Total time spent: 245.93 seconds\n",
      "Traing Acc: 0.98124\n",
      "Test Acc: 0.9618\n",
      "Validation Acc: 0.9628\n",
      "\n",
      "Creating new model\n",
      "Using Discret. Layer\n",
      "Transformer network output shape:  (None, 1, 20, 20)\n",
      "Epoch 0: Train cost 1.88105046749, Train acc 0.32526, val acc 0.5732, test acc 0.5708, took 5.95 sec.\n",
      "Epoch 1: Train cost 0.987458527088, Train acc 0.67502, val acc 0.7465, test acc 0.7412, took 6.2 sec.\n",
      "Epoch 2: Train cost 0.680048704147, Train acc 0.78008, val acc 0.8, test acc 0.7952, took 5.95 sec.\n",
      "Epoch 3: Train cost 0.541005015373, Train acc 0.82854, val acc 0.8349, test acc 0.8342, took 6.2 sec.\n",
      "Epoch 4: Train cost 0.457791149616, Train acc 0.85354, val acc 0.8631, test acc 0.8598, took 5.94 sec.\n",
      "Epoch 5: Train cost 0.392895460129, Train acc 0.87262, val acc 0.8819, test acc 0.8826, took 6.21 sec.\n",
      "Epoch 6: Train cost 0.351737856865, Train acc 0.88694, val acc 0.8934, test acc 0.8898, took 6.02 sec.\n",
      "Epoch 7: Train cost 0.299117684364, Train acc 0.90386, val acc 0.8937, test acc 0.8944, took 6.03 sec.\n",
      "Epoch 8: Train cost 0.279713213444, Train acc 0.9089, val acc 0.9076, test acc 0.9122, took 6.01 sec.\n",
      "Epoch 9: Train cost 0.261351019144, Train acc 0.91682, val acc 0.9183, test acc 0.9197, took 6.0 sec.\n",
      "Epoch 10: Train cost 0.239687994123, Train acc 0.9224, val acc 0.9187, test acc 0.9196, took 6.02 sec.\n",
      "Epoch 11: Train cost 0.216710805893, Train acc 0.92878, val acc 0.9219, test acc 0.9205, took 6.02 sec.\n",
      "Epoch 12: Train cost 0.213816851377, Train acc 0.93114, val acc 0.9297, test acc 0.929, took 6.01 sec.\n",
      "Epoch 13: Train cost 0.200146526098, Train acc 0.93586, val acc 0.9336, test acc 0.935, took 6.0 sec.\n",
      "Epoch 14: Train cost 0.191704541445, Train acc 0.93918, val acc 0.9257, test acc 0.9268, took 6.01 sec.\n",
      "Epoch 15: Train cost 0.191936507821, Train acc 0.9384, val acc 0.9204, test acc 0.9217, took 6.03 sec.\n",
      "Epoch 16: Train cost 0.181073829532, Train acc 0.94076, val acc 0.9289, test acc 0.9282, took 6.01 sec.\n",
      "Epoch 17: Train cost 0.169879987836, Train acc 0.9449, val acc 0.9366, test acc 0.9384, took 6.0 sec.\n",
      "Epoch 18: Train cost 0.162326410413, Train acc 0.94658, val acc 0.9379, test acc 0.9395, took 6.01 sec.\n",
      "New LR: 0.000700000033248\n",
      "Epoch 19: Train cost 0.156101599336, Train acc 0.94812, val acc 0.9398, test acc 0.9386, took 6.02 sec.\n",
      "Epoch 20: Train cost 0.141645118594, Train acc 0.95408, val acc 0.9421, test acc 0.9412, took 6.01 sec.\n",
      "Epoch 21: Train cost 0.134767651558, Train acc 0.95594, val acc 0.9455, test acc 0.9451, took 6.0 sec.\n",
      "Epoch 22: Train cost 0.129760757089, Train acc 0.95754, val acc 0.9471, test acc 0.9484, took 6.01 sec.\n",
      "Epoch 23: Train cost 0.121546678245, Train acc 0.96012, val acc 0.946, test acc 0.9495, took 6.02 sec.\n",
      "Epoch 24: Train cost 0.116043664515, Train acc 0.96198, val acc 0.9482, test acc 0.9526, took 6.01 sec.\n",
      "Epoch 25: Train cost 0.113972894847, Train acc 0.9624, val acc 0.9428, test acc 0.9449, took 6.0 sec.\n",
      "Epoch 26: Train cost 0.116167828441, Train acc 0.96252, val acc 0.9496, test acc 0.9503, took 6.02 sec.\n",
      "Epoch 27: Train cost 0.108619764447, Train acc 0.96406, val acc 0.9513, test acc 0.9518, took 6.02 sec.\n",
      "Epoch 28: Train cost 0.106835640967, Train acc 0.9655, val acc 0.952, test acc 0.9524, took 6.01 sec.\n",
      "Epoch 29: Train cost 0.102176733315, Train acc 0.96632, val acc 0.9488, test acc 0.9506, took 6.0 sec.\n",
      "Epoch 30: Train cost 0.0963621810079, Train acc 0.96806, val acc 0.9494, test acc 0.9483, took 6.02 sec.\n",
      "Epoch 31: Train cost 0.0950917005539, Train acc 0.96878, val acc 0.9517, test acc 0.9521, took 6.03 sec.\n",
      "Epoch 32: Train cost 0.0919169411063, Train acc 0.96986, val acc 0.9524, test acc 0.9544, took 6.01 sec.\n",
      "Epoch 33: Train cost 0.0925394743681, Train acc 0.96976, val acc 0.952, test acc 0.9525, took 6.0 sec.\n",
      "Epoch 34: Train cost 0.0855990797281, Train acc 0.97174, val acc 0.9525, test acc 0.9531, took 6.02 sec.\n",
      "Epoch 35: Train cost 0.0926719009876, Train acc 0.96858, val acc 0.9527, test acc 0.9539, took 6.03 sec.\n",
      "Epoch 36: Train cost 0.0884441435337, Train acc 0.9713, val acc 0.9547, test acc 0.9549, took 6.01 sec.\n",
      "Epoch 37: Train cost 0.0892314910889, Train acc 0.97014, val acc 0.9537, test acc 0.9538, took 6.0 sec.\n",
      "Epoch 38: Train cost 0.080611422658, Train acc 0.9737, val acc 0.9513, test acc 0.9546, took 6.01 sec.\n",
      "New LR: 0.000490000023274\n",
      "Epoch 39: Train cost 0.0802932083607, Train acc 0.97282, val acc 0.9564, test acc 0.9561, took 6.03 sec.\n",
      "Epoch 40: Train cost 0.0737428069115, Train acc 0.9758, val acc 0.9599, test acc 0.9583, took 6.01 sec.\n",
      "Epoch 41: Train cost 0.0634559318423, Train acc 0.97872, val acc 0.9609, test acc 0.9602, took 6.0 sec.\n",
      "Epoch 42: Train cost 0.062330622226, Train acc 0.9796, val acc 0.9621, test acc 0.9579, took 7.33 sec.\n",
      "Epoch 43: Train cost 0.0602328442037, Train acc 0.9802, val acc 0.9576, test acc 0.9592, took 7.09 sec.\n",
      "\n",
      "Test 3 is over, saving to history\n",
      "\n",
      "Total time spent: 267.34 seconds\n",
      "Traing Acc: 0.9802\n",
      "Test Acc: 0.9592\n",
      "Validation Acc: 0.9576\n",
      "\n",
      "Creating new model\n",
      "Using Discret. Layer\n",
      "Transformer network output shape:  (None, 1, 20, 20)\n",
      "Epoch 0: Train cost 1.82837879658, Train acc 0.3494, val acc 0.5505, test acc 0.5519, took 5.95 sec.\n",
      "Epoch 1: Train cost 1.00459361076, Train acc 0.66914, val acc 0.7209, test acc 0.7147, took 6.2 sec.\n",
      "Epoch 2: Train cost 0.723846435547, Train acc 0.76514, val acc 0.7876, test acc 0.7946, took 6.08 sec.\n",
      "Epoch 3: Train cost 0.540620923042, Train acc 0.82632, val acc 0.8335, test acc 0.841, took 6.05 sec.\n",
      "Epoch 4: Train cost 0.437396645546, Train acc 0.8595, val acc 0.8694, test acc 0.8758, took 6.0 sec.\n",
      "Epoch 5: Train cost 0.397948473692, Train acc 0.87312, val acc 0.873, test acc 0.8756, took 6.0 sec.\n",
      "Epoch 6: Train cost 0.340484321117, Train acc 0.89084, val acc 0.8985, test acc 0.8963, took 6.26 sec.\n",
      "Epoch 7: Train cost 0.312405824661, Train acc 0.8997, val acc 0.8981, test acc 0.8971, took 6.14 sec.\n",
      "Epoch 8: Train cost 0.27735877037, Train acc 0.9102, val acc 0.9134, test acc 0.9151, took 5.94 sec.\n",
      "Epoch 9: Train cost 0.262146651745, Train acc 0.91376, val acc 0.9113, test acc 0.9099, took 6.21 sec.\n",
      "Epoch 10: Train cost 0.241509765387, Train acc 0.9213, val acc 0.918, test acc 0.9158, took 5.94 sec.\n",
      "Epoch 11: Train cost 0.228189349174, Train acc 0.92706, val acc 0.9276, test acc 0.9283, took 6.2 sec.\n",
      "Epoch 12: Train cost 0.210302039981, Train acc 0.93244, val acc 0.9286, test acc 0.9312, took 5.94 sec.\n",
      "Epoch 13: Train cost 0.191133618355, Train acc 0.93756, val acc 0.9319, test acc 0.9354, took 6.19 sec.\n",
      "Epoch 14: Train cost 0.187763914466, Train acc 0.93872, val acc 0.9352, test acc 0.9347, took 5.94 sec.\n",
      "Epoch 15: Train cost 0.183910831809, Train acc 0.9412, val acc 0.9369, test acc 0.9372, took 6.21 sec.\n",
      "Epoch 16: Train cost 0.16517187655, Train acc 0.94586, val acc 0.9407, test acc 0.9393, took 6.02 sec.\n",
      "Epoch 17: Train cost 0.160247445107, Train acc 0.9476, val acc 0.9471, test acc 0.9444, took 6.03 sec.\n",
      "Epoch 18: Train cost 0.155421704054, Train acc 0.9496, val acc 0.9419, test acc 0.9406, took 6.01 sec.\n",
      "New LR: 0.000700000033248\n",
      "Epoch 19: Train cost 0.150996148586, Train acc 0.95156, val acc 0.9376, test acc 0.9372, took 5.97 sec.\n",
      "Epoch 20: Train cost 0.130785942078, Train acc 0.95694, val acc 0.9502, test acc 0.9496, took 5.94 sec.\n",
      "Epoch 21: Train cost 0.121947549284, Train acc 0.95994, val acc 0.947, test acc 0.9481, took 6.21 sec.\n",
      "Epoch 22: Train cost 0.117107115686, Train acc 0.9626, val acc 0.951, test acc 0.9505, took 6.01 sec.\n",
      "Epoch 23: Train cost 0.112406983972, Train acc 0.96316, val acc 0.9539, test acc 0.9535, took 6.02 sec.\n",
      "Epoch 24: Train cost 0.108880929649, Train acc 0.96446, val acc 0.9486, test acc 0.9477, took 6.0 sec.\n",
      "Epoch 25: Train cost 0.111390694976, Train acc 0.96274, val acc 0.9508, test acc 0.9529, took 5.99 sec.\n",
      "Epoch 26: Train cost 0.109188623726, Train acc 0.9642, val acc 0.9578, test acc 0.9529, took 6.01 sec.\n",
      "Epoch 27: Train cost 0.095846273005, Train acc 0.96768, val acc 0.9529, test acc 0.9551, took 6.02 sec.\n",
      "Epoch 28: Train cost 0.0987677946687, Train acc 0.9671, val acc 0.9531, test acc 0.9516, took 6.0 sec.\n",
      "Epoch 29: Train cost 0.0957383140922, Train acc 0.96826, val acc 0.9545, test acc 0.956, took 5.99 sec.\n",
      "Epoch 30: Train cost 0.0942875146866, Train acc 0.96918, val acc 0.9506, test acc 0.9486, took 6.01 sec.\n",
      "Epoch 31: Train cost 0.0924696624279, Train acc 0.96906, val acc 0.9512, test acc 0.9511, took 6.02 sec.\n",
      "Epoch 32: Train cost 0.0860893800855, Train acc 0.9711, val acc 0.9562, test acc 0.9583, took 6.0 sec.\n",
      "Epoch 33: Train cost 0.0851557776332, Train acc 0.97158, val acc 0.9578, test acc 0.958, took 5.99 sec.\n",
      "Epoch 34: Train cost 0.0898614600301, Train acc 0.9701, val acc 0.9552, test acc 0.9572, took 6.0 sec.\n",
      "Epoch 35: Train cost 0.0882175564766, Train acc 0.96992, val acc 0.9552, test acc 0.9594, took 6.02 sec.\n",
      "Epoch 36: Train cost 0.0856013670564, Train acc 0.97174, val acc 0.9527, test acc 0.9538, took 6.0 sec.\n",
      "Epoch 37: Train cost 0.0801408886909, Train acc 0.97306, val acc 0.9534, test acc 0.9571, took 5.98 sec.\n",
      "Epoch 38: Train cost 0.0790416672826, Train acc 0.97382, val acc 0.9542, test acc 0.9541, took 6.01 sec.\n",
      "New LR: 0.000490000023274\n",
      "Epoch 39: Train cost 0.0762889310718, Train acc 0.97532, val acc 0.9562, test acc 0.9561, took 6.02 sec.\n",
      "Epoch 40: Train cost 0.0659416466951, Train acc 0.97842, val acc 0.9602, test acc 0.9611, took 6.0 sec.\n",
      "Epoch 41: Train cost 0.0590290538967, Train acc 0.97972, val acc 0.9604, test acc 0.9599, took 5.98 sec.\n",
      "Epoch 42: Train cost 0.058146186173, Train acc 0.98096, val acc 0.9615, test acc 0.9631, took 6.01 sec.\n",
      "\n",
      "Test 4 is over, saving to history\n",
      "\n",
      "Total time spent: 259.5 seconds\n",
      "Traing Acc: 0.98096\n",
      "Test Acc: 0.9631\n",
      "Validation Acc: 0.9615\n",
      "\n",
      "Creating new model\n",
      "Using Discret. Layer\n",
      "Transformer network output shape:  (None, 1, 20, 20)\n",
      "Epoch 0: Train cost 1.81653988361, Train acc 0.34996, val acc 0.5911, test acc 0.5953, took 5.93 sec.\n",
      "Epoch 1: Train cost 0.891111731529, Train acc 0.7078, val acc 0.7741, test acc 0.7743, took 6.11 sec.\n",
      "Epoch 2: Train cost 0.603715717793, Train acc 0.80504, val acc 0.8202, test acc 0.8208, took 6.11 sec.\n",
      "Epoch 3: Train cost 0.471620976925, Train acc 0.84768, val acc 0.8672, test acc 0.8692, took 6.0 sec.\n",
      "Epoch 4: Train cost 0.398350685835, Train acc 0.87186, val acc 0.8584, test acc 0.8574, took 5.97 sec.\n",
      "Epoch 5: Train cost 0.335896015167, Train acc 0.89156, val acc 0.8925, test acc 0.8899, took 5.93 sec.\n",
      "Epoch 6: Train cost 0.301431179047, Train acc 0.90236, val acc 0.9015, test acc 0.8997, took 6.21 sec.\n",
      "Epoch 7: Train cost 0.290428519249, Train acc 0.90638, val acc 0.9148, test acc 0.9088, took 6.01 sec.\n",
      "Epoch 8: Train cost 0.256035476923, Train acc 0.91858, val acc 0.9198, test acc 0.9191, took 6.02 sec.\n",
      "Epoch 9: Train cost 0.228796452284, Train acc 0.92652, val acc 0.9241, test acc 0.9213, took 6.0 sec.\n",
      "Epoch 10: Train cost 0.206799134612, Train acc 0.93294, val acc 0.9241, test acc 0.9269, took 5.98 sec.\n",
      "Epoch 11: Train cost 0.204717636108, Train acc 0.93334, val acc 0.9293, test acc 0.9354, took 6.01 sec.\n",
      "Epoch 12: Train cost 0.187939494848, Train acc 0.939, val acc 0.9332, test acc 0.9369, took 6.02 sec.\n",
      "Epoch 13: Train cost 0.182775422931, Train acc 0.9408, val acc 0.9317, test acc 0.9338, took 6.0 sec.\n",
      "Epoch 14: Train cost 0.184573471546, Train acc 0.94046, val acc 0.9388, test acc 0.9426, took 5.98 sec.\n",
      "Epoch 15: Train cost 0.165556281805, Train acc 0.94604, val acc 0.9402, test acc 0.943, took 6.01 sec.\n",
      "Epoch 16: Train cost 0.173347830772, Train acc 0.94434, val acc 0.9309, test acc 0.9315, took 6.02 sec.\n",
      "Epoch 17: Train cost 0.164379432797, Train acc 0.94626, val acc 0.9299, test acc 0.9332, took 6.0 sec.\n",
      "Epoch 18: Train cost 0.14516890049, Train acc 0.95366, val acc 0.9336, test acc 0.9331, took 5.98 sec.\n",
      "New LR: 0.000700000033248\n",
      "Epoch 19: Train cost 0.136298581958, Train acc 0.95572, val acc 0.9466, test acc 0.9469, took 6.01 sec.\n",
      "Epoch 20: Train cost 0.122939012945, Train acc 0.95994, val acc 0.9518, test acc 0.9531, took 6.02 sec.\n",
      "Epoch 21: Train cost 0.112676389515, Train acc 0.96316, val acc 0.949, test acc 0.9519, took 5.99 sec.\n",
      "Epoch 22: Train cost 0.109994739294, Train acc 0.96384, val acc 0.9519, test acc 0.948, took 5.98 sec.\n",
      "Epoch 23: Train cost 0.10754763335, Train acc 0.9658, val acc 0.9541, test acc 0.9541, took 6.01 sec.\n",
      "Epoch 24: Train cost 0.103872686625, Train acc 0.96584, val acc 0.9517, test acc 0.9531, took 6.02 sec.\n",
      "Epoch 25: Train cost 0.0962846428156, Train acc 0.96834, val acc 0.9551, test acc 0.9572, took 6.0 sec.\n",
      "Epoch 26: Train cost 0.0988793894649, Train acc 0.96724, val acc 0.9577, test acc 0.9564, took 5.98 sec.\n",
      "Epoch 27: Train cost 0.0918322578073, Train acc 0.9705, val acc 0.953, test acc 0.9532, took 6.0 sec.\n",
      "Epoch 28: Train cost 0.0911966636777, Train acc 0.9694, val acc 0.9584, test acc 0.9603, took 6.02 sec.\n",
      "Epoch 29: Train cost 0.0921058878303, Train acc 0.96938, val acc 0.9527, test acc 0.9567, took 6.0 sec.\n",
      "Epoch 30: Train cost 0.0889330878854, Train acc 0.96992, val acc 0.9529, test acc 0.956, took 5.98 sec.\n",
      "Epoch 31: Train cost 0.0887452363968, Train acc 0.97096, val acc 0.9578, test acc 0.959, took 6.01 sec.\n",
      "Epoch 32: Train cost 0.0788997039199, Train acc 0.97318, val acc 0.9564, test acc 0.9575, took 6.02 sec.\n",
      "Epoch 33: Train cost 0.0742514058948, Train acc 0.97562, val acc 0.9554, test acc 0.9572, took 5.99 sec.\n",
      "Epoch 34: Train cost 0.0797643736005, Train acc 0.97338, val acc 0.9599, test acc 0.9577, took 5.98 sec.\n",
      "Epoch 35: Train cost 0.0709646940231, Train acc 0.97678, val acc 0.9612, test acc 0.9607, took 6.01 sec.\n",
      "Epoch 36: Train cost 0.0714335739613, Train acc 0.97618, val acc 0.9584, test acc 0.9579, took 6.02 sec.\n",
      "Epoch 37: Train cost 0.0777866318822, Train acc 0.9746, val acc 0.9574, test acc 0.9566, took 5.99 sec.\n",
      "Epoch 38: Train cost 0.0694306045771, Train acc 0.9767, val acc 0.9569, test acc 0.9599, took 5.98 sec.\n",
      "New LR: 0.000490000023274\n",
      "Epoch 39: Train cost 0.0700536444783, Train acc 0.97678, val acc 0.9601, test acc 0.9619, took 6.0 sec.\n",
      "Epoch 40: Train cost 0.0574660971761, Train acc 0.9813, val acc 0.9601, test acc 0.962, took 6.02 sec.\n",
      "\n",
      "Test 5 is over, saving to history\n",
      "\n",
      "Total time spent: 246.33 seconds\n",
      "Traing Acc: 0.9813\n",
      "Test Acc: 0.962\n",
      "Validation Acc: 0.9601\n",
      "\n",
      "Creating new model\n",
      "Using Discret. Layer\n",
      "Transformer network output shape:  (None, 1, 20, 20)\n",
      "Epoch 0: Train cost 1.84392595291, Train acc 0.33938, val acc 0.5141, test acc 0.519, took 5.93 sec.\n",
      "Epoch 1: Train cost 0.944649517536, Train acc 0.68642, val acc 0.7611, test acc 0.7567, took 6.2 sec.\n",
      "Epoch 2: Train cost 0.682516217232, Train acc 0.7787, val acc 0.8072, test acc 0.8045, took 6.0 sec.\n",
      "Epoch 3: Train cost 0.523518443108, Train acc 0.83134, val acc 0.8321, test acc 0.8386, took 6.01 sec.\n",
      "Epoch 4: Train cost 0.426987797022, Train acc 0.86284, val acc 0.8699, test acc 0.8714, took 5.99 sec.\n",
      "Epoch 5: Train cost 0.369133144617, Train acc 0.88012, val acc 0.8786, test acc 0.8855, took 5.98 sec.\n",
      "Epoch 6: Train cost 0.343317300081, Train acc 0.88948, val acc 0.896, test acc 0.8973, took 6.01 sec.\n",
      "Epoch 7: Train cost 0.308137953281, Train acc 0.9007, val acc 0.8997, test acc 0.9013, took 6.01 sec.\n",
      "Epoch 8: Train cost 0.281035870314, Train acc 0.91016, val acc 0.9061, test acc 0.9052, took 5.99 sec.\n",
      "Epoch 9: Train cost 0.261712163687, Train acc 0.91522, val acc 0.9115, test acc 0.9152, took 5.97 sec.\n",
      "Epoch 10: Train cost 0.238520115614, Train acc 0.92188, val acc 0.92, test acc 0.9231, took 6.0 sec.\n",
      "Epoch 11: Train cost 0.223926350474, Train acc 0.92718, val acc 0.9208, test acc 0.9206, took 6.02 sec.\n",
      "Epoch 12: Train cost 0.210859447718, Train acc 0.93192, val acc 0.9254, test acc 0.9219, took 5.99 sec.\n",
      "Epoch 13: Train cost 0.210762023926, Train acc 0.93228, val acc 0.918, test acc 0.9201, took 5.97 sec.\n",
      "Epoch 14: Train cost 0.195305928588, Train acc 0.93472, val acc 0.9287, test acc 0.9319, took 6.0 sec.\n",
      "Epoch 15: Train cost 0.1950802356, Train acc 0.9367, val acc 0.9368, test acc 0.9394, took 6.01 sec.\n",
      "Epoch 16: Train cost 0.174216389656, Train acc 0.94304, val acc 0.9328, test acc 0.9393, took 5.99 sec.\n",
      "Epoch 17: Train cost 0.163361445069, Train acc 0.94682, val acc 0.9364, test acc 0.939, took 5.96 sec.\n",
      "Epoch 18: Train cost 0.161832213402, Train acc 0.94666, val acc 0.9325, test acc 0.9362, took 5.92 sec.\n",
      "New LR: 0.000700000033248\n",
      "Epoch 19: Train cost 0.15373711288, Train acc 0.94946, val acc 0.9417, test acc 0.9453, took 6.19 sec.\n",
      "Epoch 20: Train cost 0.137585073709, Train acc 0.95458, val acc 0.9445, test acc 0.9481, took 5.99 sec.\n",
      "Epoch 21: Train cost 0.128537431359, Train acc 0.95808, val acc 0.9454, test acc 0.9496, took 6.01 sec.\n",
      "Epoch 22: Train cost 0.127142697573, Train acc 0.95788, val acc 0.9485, test acc 0.9453, took 5.99 sec.\n",
      "Epoch 23: Train cost 0.120606265962, Train acc 0.96002, val acc 0.9474, test acc 0.951, took 5.96 sec.\n",
      "Epoch 24: Train cost 0.115248166025, Train acc 0.96264, val acc 0.9426, test acc 0.9438, took 5.92 sec.\n",
      "Epoch 25: Train cost 0.120489686728, Train acc 0.96026, val acc 0.9403, test acc 0.9427, took 6.19 sec.\n",
      "Epoch 26: Train cost 0.121516644955, Train acc 0.95984, val acc 0.9443, test acc 0.9472, took 6.0 sec.\n",
      "Epoch 27: Train cost 0.106545895338, Train acc 0.9642, val acc 0.9469, test acc 0.9525, took 6.01 sec.\n",
      "Epoch 28: Train cost 0.103905968368, Train acc 0.96592, val acc 0.9509, test acc 0.9503, took 5.99 sec.\n",
      "Epoch 29: Train cost 0.108282670379, Train acc 0.96454, val acc 0.9474, test acc 0.9454, took 5.97 sec.\n",
      "Epoch 30: Train cost 0.105507150292, Train acc 0.96486, val acc 0.9524, test acc 0.9496, took 5.99 sec.\n",
      "Epoch 31: Train cost 0.0977496877313, Train acc 0.9674, val acc 0.9505, test acc 0.9499, took 6.02 sec.\n",
      "Epoch 32: Train cost 0.100157238543, Train acc 0.96764, val acc 0.9446, test acc 0.9505, took 5.99 sec.\n",
      "Epoch 33: Train cost 0.089585930109, Train acc 0.96982, val acc 0.9515, test acc 0.9516, took 5.98 sec.\n",
      "Epoch 34: Train cost 0.0884334445, Train acc 0.97084, val acc 0.9533, test acc 0.9526, took 6.0 sec.\n",
      "Epoch 35: Train cost 0.0960213765502, Train acc 0.96774, val acc 0.9542, test acc 0.9536, took 6.01 sec.\n",
      "Epoch 36: Train cost 0.0927961990237, Train acc 0.96888, val acc 0.9527, test acc 0.9551, took 5.99 sec.\n",
      "Epoch 37: Train cost 0.0872305855155, Train acc 0.97112, val acc 0.9473, test acc 0.9513, took 5.97 sec.\n",
      "Epoch 38: Train cost 0.085449591279, Train acc 0.97122, val acc 0.9508, test acc 0.9515, took 6.0 sec.\n",
      "New LR: 0.000490000023274\n",
      "Epoch 39: Train cost 0.0779620781541, Train acc 0.9742, val acc 0.9474, test acc 0.9502, took 6.01 sec.\n",
      "Epoch 40: Train cost 0.074269361794, Train acc 0.97524, val acc 0.9557, test acc 0.9578, took 5.98 sec.\n",
      "Epoch 41: Train cost 0.0637470930815, Train acc 0.97932, val acc 0.9546, test acc 0.9576, took 5.98 sec.\n",
      "Epoch 42: Train cost 0.0603294745088, Train acc 0.98032, val acc 0.9548, test acc 0.9561, took 6.0 sec.\n",
      "\n",
      "Test 6 is over, saving to history\n",
      "\n",
      "Total time spent: 258.1 seconds\n",
      "Traing Acc: 0.98032\n",
      "Test Acc: 0.9561\n",
      "Validation Acc: 0.9548\n",
      "\n",
      "Creating new model\n",
      "Using Discret. Layer\n",
      "Transformer network output shape:  (None, 1, 20, 20)\n",
      "Epoch 0: Train cost 1.84006536007, Train acc 0.34176, val acc 0.5454, test acc 0.5448, took 5.92 sec.\n",
      "Epoch 1: Train cost 1.00174760818, Train acc 0.67052, val acc 0.7451, test acc 0.742, took 6.09 sec.\n",
      "Epoch 2: Train cost 0.677710533142, Train acc 0.7814, val acc 0.8003, test acc 0.8048, took 6.13 sec.\n",
      "Epoch 3: Train cost 0.547163724899, Train acc 0.82364, val acc 0.8491, test acc 0.8396, took 5.99 sec.\n",
      "Epoch 4: Train cost 0.466171145439, Train acc 0.85144, val acc 0.8569, test acc 0.8589, took 5.98 sec.\n",
      "Epoch 5: Train cost 0.394382506609, Train acc 0.87424, val acc 0.8709, test acc 0.8764, took 5.93 sec.\n",
      "Epoch 6: Train cost 0.352991104126, Train acc 0.88648, val acc 0.882, test acc 0.883, took 6.19 sec.\n",
      "Epoch 7: Train cost 0.313247412443, Train acc 0.89954, val acc 0.8995, test acc 0.8948, took 6.01 sec.\n",
      "Epoch 8: Train cost 0.288018792868, Train acc 0.90768, val acc 0.9, test acc 0.8969, took 6.02 sec.\n",
      "Epoch 9: Train cost 0.266212970018, Train acc 0.91412, val acc 0.9125, test acc 0.911, took 5.99 sec.\n",
      "Epoch 10: Train cost 0.257551163435, Train acc 0.9176, val acc 0.9083, test acc 0.9051, took 5.97 sec.\n",
      "Epoch 11: Train cost 0.239331230521, Train acc 0.92516, val acc 0.9228, test acc 0.9227, took 5.93 sec.\n",
      "Epoch 12: Train cost 0.217685043812, Train acc 0.9304, val acc 0.9291, test acc 0.9259, took 6.2 sec.\n",
      "Epoch 13: Train cost 0.200722754002, Train acc 0.9338, val acc 0.9311, test acc 0.9312, took 6.0 sec.\n",
      "Epoch 14: Train cost 0.197814434767, Train acc 0.93548, val acc 0.9273, test acc 0.9286, took 6.02 sec.\n",
      "Epoch 15: Train cost 0.191201075912, Train acc 0.93852, val acc 0.9236, test acc 0.9285, took 5.99 sec.\n",
      "Epoch 16: Train cost 0.178079366684, Train acc 0.94204, val acc 0.9338, test acc 0.9379, took 5.98 sec.\n",
      "Epoch 17: Train cost 0.164213180542, Train acc 0.94692, val acc 0.931, test acc 0.933, took 6.01 sec.\n",
      "Epoch 18: Train cost 0.163545429707, Train acc 0.94642, val acc 0.937, test acc 0.9394, took 6.01 sec.\n",
      "New LR: 0.000700000033248\n",
      "Epoch 19: Train cost 0.16492664814, Train acc 0.94506, val acc 0.9374, test acc 0.9383, took 5.99 sec.\n",
      "Epoch 20: Train cost 0.144795268774, Train acc 0.95278, val acc 0.9412, test acc 0.9423, took 5.96 sec.\n",
      "Epoch 21: Train cost 0.131705343723, Train acc 0.95686, val acc 0.9424, test acc 0.9415, took 5.98 sec.\n",
      "Epoch 22: Train cost 0.133827447891, Train acc 0.95546, val acc 0.9472, test acc 0.9427, took 6.2 sec.\n",
      "Epoch 23: Train cost 0.129317447543, Train acc 0.95742, val acc 0.9486, test acc 0.946, took 6.0 sec.\n",
      "Epoch 24: Train cost 0.129537463188, Train acc 0.95722, val acc 0.9509, test acc 0.9497, took 6.02 sec.\n",
      "Epoch 25: Train cost 0.11515724659, Train acc 0.9625, val acc 0.9481, test acc 0.9473, took 5.99 sec.\n",
      "Epoch 26: Train cost 0.117761045694, Train acc 0.961, val acc 0.9489, test acc 0.9501, took 5.96 sec.\n",
      "Epoch 27: Train cost 0.109991237521, Train acc 0.9638, val acc 0.9487, test acc 0.9454, took 5.92 sec.\n",
      "Epoch 28: Train cost 0.109766863286, Train acc 0.96314, val acc 0.95, test acc 0.9495, took 6.2 sec.\n",
      "Epoch 29: Train cost 0.100280955434, Train acc 0.96688, val acc 0.9492, test acc 0.9491, took 6.0 sec.\n",
      "Epoch 30: Train cost 0.0984707847238, Train acc 0.9682, val acc 0.9508, test acc 0.9529, took 6.02 sec.\n",
      "Epoch 31: Train cost 0.0999481827021, Train acc 0.96638, val acc 0.9516, test acc 0.9513, took 5.99 sec.\n",
      "Epoch 32: Train cost 0.0964794158936, Train acc 0.96808, val acc 0.9505, test acc 0.9506, took 5.96 sec.\n",
      "Epoch 33: Train cost 0.0915831327438, Train acc 0.96986, val acc 0.9514, test acc 0.9493, took 5.92 sec.\n",
      "Epoch 34: Train cost 0.0896916687489, Train acc 0.9703, val acc 0.9538, test acc 0.9535, took 6.2 sec.\n",
      "Epoch 35: Train cost 0.0918902829289, Train acc 0.96944, val acc 0.9493, test acc 0.949, took 6.0 sec.\n",
      "Epoch 36: Train cost 0.0906726717949, Train acc 0.96944, val acc 0.9548, test acc 0.9548, took 6.01 sec.\n",
      "Epoch 37: Train cost 0.0883875489235, Train acc 0.9698, val acc 0.9544, test acc 0.955, took 6.0 sec.\n",
      "Epoch 38: Train cost 0.0817394480109, Train acc 0.97336, val acc 0.9545, test acc 0.956, took 5.99 sec.\n",
      "New LR: 0.000490000023274\n",
      "Epoch 39: Train cost 0.0794217959046, Train acc 0.97314, val acc 0.9571, test acc 0.9534, took 6.01 sec.\n",
      "Epoch 40: Train cost 0.0692633241415, Train acc 0.9767, val acc 0.9574, test acc 0.9566, took 6.02 sec.\n",
      "Epoch 41: Train cost 0.0635429993272, Train acc 0.9793, val acc 0.9583, test acc 0.9548, took 5.99 sec.\n",
      "Epoch 42: Train cost 0.0618474669755, Train acc 0.97938, val acc 0.9583, test acc 0.953, took 5.98 sec.\n",
      "Epoch 43: Train cost 0.0611514747143, Train acc 0.97824, val acc 0.9578, test acc 0.9575, took 6.0 sec.\n",
      "Epoch 44: Train cost 0.0603591650724, Train acc 0.97962, val acc 0.9555, test acc 0.9545, took 6.02 sec.\n",
      "Epoch 45: Train cost 0.0548574887216, Train acc 0.98174, val acc 0.9564, test acc 0.955, took 5.99 sec.\n",
      "\n",
      "Test 7 is over, saving to history\n",
      "\n",
      "Total time spent: 276.69 seconds\n",
      "Traing Acc: 0.98174\n",
      "Test Acc: 0.955\n",
      "Validation Acc: 0.9564\n",
      "\n",
      "Creating new model\n",
      "Using Discret. Layer\n",
      "Transformer network output shape:  (None, 1, 20, 20)\n",
      "Epoch 0: Train cost 1.86191475391, Train acc 0.32958, val acc 0.5008, test acc 0.4953, took 5.94 sec.\n",
      "Epoch 1: Train cost 1.04302680492, Train acc 0.6506, val acc 0.7494, test acc 0.7535, took 6.13 sec.\n",
      "Epoch 2: Train cost 0.688338160515, Train acc 0.77488, val acc 0.7932, test acc 0.7913, took 6.11 sec.\n",
      "Epoch 3: Train cost 0.545766532421, Train acc 0.82402, val acc 0.8414, test acc 0.838, took 6.02 sec.\n",
      "Epoch 4: Train cost 0.435504049063, Train acc 0.86068, val acc 0.8739, test acc 0.8709, took 6.0 sec.\n",
      "Epoch 5: Train cost 0.383572816849, Train acc 0.87604, val acc 0.8829, test acc 0.881, took 6.02 sec.\n",
      "Epoch 6: Train cost 0.338065326214, Train acc 0.89176, val acc 0.8899, test acc 0.8905, took 6.02 sec.\n",
      "Epoch 7: Train cost 0.313827425241, Train acc 0.89902, val acc 0.904, test acc 0.9066, took 6.01 sec.\n",
      "Epoch 8: Train cost 0.275018900633, Train acc 0.91222, val acc 0.9121, test acc 0.9137, took 6.0 sec.\n",
      "Epoch 9: Train cost 0.260445177555, Train acc 0.91518, val acc 0.9129, test acc 0.9164, took 6.02 sec.\n",
      "Epoch 10: Train cost 0.237289816141, Train acc 0.9227, val acc 0.9137, test acc 0.9159, took 6.02 sec.\n",
      "Epoch 11: Train cost 0.22866217792, Train acc 0.92696, val acc 0.9211, test acc 0.916, took 6.01 sec.\n",
      "Epoch 12: Train cost 0.21223397553, Train acc 0.9312, val acc 0.9231, test acc 0.9262, took 6.0 sec.\n",
      "Epoch 13: Train cost 0.193636402488, Train acc 0.93758, val acc 0.9359, test acc 0.939, took 6.01 sec.\n",
      "Epoch 14: Train cost 0.177157580853, Train acc 0.94248, val acc 0.9284, test acc 0.9357, took 6.02 sec.\n",
      "Epoch 15: Train cost 0.171090230346, Train acc 0.94416, val acc 0.9312, test acc 0.9351, took 6.01 sec.\n",
      "Epoch 16: Train cost 0.169419497252, Train acc 0.9454, val acc 0.9329, test acc 0.9364, took 6.0 sec.\n",
      "Epoch 17: Train cost 0.156864777207, Train acc 0.94884, val acc 0.9334, test acc 0.9324, took 6.01 sec.\n",
      "Epoch 18: Train cost 0.150397285819, Train acc 0.9504, val acc 0.9461, test acc 0.9468, took 6.02 sec.\n",
      "New LR: 0.000700000033248\n",
      "Epoch 19: Train cost 0.146512761712, Train acc 0.95148, val acc 0.9356, test acc 0.9356, took 6.01 sec.\n",
      "Epoch 20: Train cost 0.132041662931, Train acc 0.95644, val acc 0.9466, test acc 0.9492, took 5.99 sec.\n",
      "Epoch 21: Train cost 0.116398304701, Train acc 0.96216, val acc 0.9493, test acc 0.9464, took 6.01 sec.\n",
      "Epoch 22: Train cost 0.117251046002, Train acc 0.9614, val acc 0.9465, test acc 0.9489, took 6.02 sec.\n",
      "Epoch 23: Train cost 0.112904936075, Train acc 0.96342, val acc 0.9533, test acc 0.9526, took 6.0 sec.\n",
      "Epoch 24: Train cost 0.114536121488, Train acc 0.96186, val acc 0.95, test acc 0.9486, took 5.99 sec.\n",
      "Epoch 25: Train cost 0.105516240001, Train acc 0.96506, val acc 0.9532, test acc 0.9486, took 6.0 sec.\n",
      "Epoch 26: Train cost 0.106211222708, Train acc 0.96522, val acc 0.9529, test acc 0.9525, took 6.02 sec.\n",
      "Epoch 27: Train cost 0.103867061436, Train acc 0.96474, val acc 0.9529, test acc 0.9483, took 6.01 sec.\n",
      "Epoch 28: Train cost 0.100647188723, Train acc 0.96704, val acc 0.9549, test acc 0.9511, took 5.99 sec.\n",
      "Epoch 29: Train cost 0.100887045264, Train acc 0.9666, val acc 0.9474, test acc 0.9487, took 6.01 sec.\n",
      "Epoch 30: Train cost 0.0923424735665, Train acc 0.96942, val acc 0.9521, test acc 0.9523, took 6.02 sec.\n",
      "Epoch 31: Train cost 0.0959730893373, Train acc 0.96838, val acc 0.9515, test acc 0.9528, took 6.0 sec.\n",
      "Epoch 32: Train cost 0.0877654775977, Train acc 0.9714, val acc 0.9514, test acc 0.9492, took 5.99 sec.\n",
      "Epoch 33: Train cost 0.0872718244791, Train acc 0.9705, val acc 0.9548, test acc 0.9552, took 6.0 sec.\n",
      "Epoch 34: Train cost 0.0947975218296, Train acc 0.96868, val acc 0.9486, test acc 0.9505, took 6.01 sec.\n",
      "Epoch 35: Train cost 0.0814670473337, Train acc 0.97266, val acc 0.9601, test acc 0.9559, took 6.0 sec.\n",
      "Epoch 36: Train cost 0.075333558023, Train acc 0.97382, val acc 0.9573, test acc 0.9559, took 5.99 sec.\n",
      "Epoch 37: Train cost 0.079226590693, Train acc 0.97334, val acc 0.9554, test acc 0.9521, took 6.01 sec.\n",
      "Epoch 38: Train cost 0.0789288207889, Train acc 0.9741, val acc 0.9534, test acc 0.9562, took 6.01 sec.\n",
      "New LR: 0.000490000023274\n",
      "Epoch 39: Train cost 0.0719894170761, Train acc 0.97524, val acc 0.9583, test acc 0.9582, took 6.0 sec.\n",
      "Epoch 40: Train cost 0.0625473111868, Train acc 0.97864, val acc 0.9575, test acc 0.9561, took 5.99 sec.\n",
      "Epoch 41: Train cost 0.0595784783363, Train acc 0.98044, val acc 0.9593, test acc 0.958, took 6.0 sec.\n",
      "\n",
      "Test 8 is over, saving to history\n",
      "\n",
      "Total time spent: 252.42 seconds\n",
      "Traing Acc: 0.98044\n",
      "Test Acc: 0.958\n",
      "Validation Acc: 0.9593\n",
      "\n",
      "Creating new model\n",
      "Using Discret. Layer\n",
      "Transformer network output shape:  (None, 1, 20, 20)\n",
      "Epoch 0: Train cost 1.89219725132, Train acc 0.32256, val acc 0.4975, test acc 0.5036, took 5.95 sec.\n",
      "Epoch 1: Train cost 1.08387339115, Train acc 0.63876, val acc 0.72, test acc 0.7143, took 6.15 sec.\n",
      "Epoch 2: Train cost 0.737488389015, Train acc 0.76278, val acc 0.8064, test acc 0.7974, took 6.11 sec.\n",
      "Epoch 3: Train cost 0.565194249153, Train acc 0.81646, val acc 0.8344, test acc 0.8374, took 6.02 sec.\n",
      "Epoch 4: Train cost 0.468028157949, Train acc 0.84982, val acc 0.8417, test acc 0.8434, took 6.01 sec.\n",
      "Epoch 5: Train cost 0.405204385519, Train acc 0.86986, val acc 0.87, test acc 0.8701, took 6.02 sec.\n",
      "Epoch 6: Train cost 0.352371305227, Train acc 0.88616, val acc 0.8944, test acc 0.9002, took 6.04 sec.\n",
      "Epoch 7: Train cost 0.331105440855, Train acc 0.89272, val acc 0.9058, test acc 0.9075, took 6.02 sec.\n",
      "Epoch 8: Train cost 0.2782317698, Train acc 0.9116, val acc 0.9118, test acc 0.9135, took 6.0 sec.\n",
      "Epoch 9: Train cost 0.256122857332, Train acc 0.91824, val acc 0.9157, test acc 0.9215, took 6.02 sec.\n",
      "Epoch 10: Train cost 0.234536573291, Train acc 0.92348, val acc 0.9181, test acc 0.9183, took 6.03 sec.\n",
      "Epoch 11: Train cost 0.231925114989, Train acc 0.92322, val acc 0.9271, test acc 0.9265, took 6.01 sec.\n",
      "Epoch 12: Train cost 0.216153040528, Train acc 0.93118, val acc 0.9127, test acc 0.9139, took 6.0 sec.\n",
      "Epoch 13: Train cost 0.203379228711, Train acc 0.93404, val acc 0.9273, test acc 0.9281, took 6.01 sec.\n",
      "Epoch 14: Train cost 0.191230580211, Train acc 0.93806, val acc 0.9323, test acc 0.9341, took 6.02 sec.\n",
      "Epoch 15: Train cost 0.191637188196, Train acc 0.93704, val acc 0.9328, test acc 0.9361, took 6.01 sec.\n",
      "Epoch 16: Train cost 0.176046103239, Train acc 0.94268, val acc 0.9327, test acc 0.9323, took 6.0 sec.\n",
      "Epoch 17: Train cost 0.175573393703, Train acc 0.9426, val acc 0.9367, test acc 0.9359, took 6.01 sec.\n",
      "Epoch 18: Train cost 0.161723047495, Train acc 0.94696, val acc 0.9389, test acc 0.9399, took 6.03 sec.\n",
      "New LR: 0.000700000033248\n",
      "Epoch 19: Train cost 0.149338960648, Train acc 0.95194, val acc 0.9433, test acc 0.9432, took 6.02 sec.\n",
      "Epoch 20: Train cost 0.136367306113, Train acc 0.95622, val acc 0.9436, test acc 0.9466, took 5.99 sec.\n",
      "Epoch 21: Train cost 0.132048487663, Train acc 0.95652, val acc 0.9474, test acc 0.947, took 6.01 sec.\n",
      "Epoch 22: Train cost 0.124046303332, Train acc 0.95856, val acc 0.9499, test acc 0.9476, took 6.02 sec.\n",
      "Epoch 23: Train cost 0.120347350836, Train acc 0.96022, val acc 0.9461, test acc 0.9469, took 6.01 sec.\n",
      "Epoch 24: Train cost 0.116809375584, Train acc 0.96196, val acc 0.949, test acc 0.9492, took 6.0 sec.\n",
      "Epoch 25: Train cost 0.112455517054, Train acc 0.96296, val acc 0.9445, test acc 0.9459, took 6.01 sec.\n",
      "Epoch 26: Train cost 0.10818580538, Train acc 0.96392, val acc 0.9534, test acc 0.9537, took 6.02 sec.\n",
      "Epoch 27: Train cost 0.105934545398, Train acc 0.9655, val acc 0.9466, test acc 0.9463, took 6.01 sec.\n",
      "Epoch 28: Train cost 0.107284232974, Train acc 0.96432, val acc 0.9518, test acc 0.9531, took 5.99 sec.\n",
      "Epoch 29: Train cost 0.102669462562, Train acc 0.96602, val acc 0.952, test acc 0.9514, took 6.0 sec.\n",
      "Epoch 30: Train cost 0.101159565151, Train acc 0.96636, val acc 0.9512, test acc 0.9482, took 6.02 sec.\n",
      "Epoch 31: Train cost 0.105519257486, Train acc 0.96574, val acc 0.953, test acc 0.9521, took 6.01 sec.\n",
      "Epoch 32: Train cost 0.091529071331, Train acc 0.9705, val acc 0.955, test acc 0.9507, took 5.99 sec.\n",
      "Epoch 33: Train cost 0.0977567955852, Train acc 0.96758, val acc 0.9559, test acc 0.9562, took 6.0 sec.\n",
      "Epoch 34: Train cost 0.0962272658944, Train acc 0.96854, val acc 0.9562, test acc 0.9545, took 6.02 sec.\n",
      "Epoch 35: Train cost 0.0856050401926, Train acc 0.97164, val acc 0.9567, test acc 0.9554, took 6.01 sec.\n",
      "Epoch 36: Train cost 0.0934148132801, Train acc 0.96842, val acc 0.9526, test acc 0.9514, took 6.0 sec.\n",
      "Epoch 37: Train cost 0.0847638770938, Train acc 0.97136, val acc 0.9564, test acc 0.9546, took 6.01 sec.\n",
      "Epoch 38: Train cost 0.0859471559525, Train acc 0.97156, val acc 0.9553, test acc 0.956, took 6.02 sec.\n",
      "New LR: 0.000490000023274\n",
      "Epoch 39: Train cost 0.0803155303001, Train acc 0.97336, val acc 0.9554, test acc 0.9559, took 6.01 sec.\n",
      "Epoch 40: Train cost 0.0778550729156, Train acc 0.97474, val acc 0.9615, test acc 0.9566, took 5.99 sec.\n",
      "Epoch 41: Train cost 0.0686748549342, Train acc 0.97706, val acc 0.9622, test acc 0.9567, took 6.0 sec.\n",
      "Epoch 42: Train cost 0.0628153309226, Train acc 0.97914, val acc 0.9596, test acc 0.9588, took 6.02 sec.\n",
      "Epoch 43: Train cost 0.0649001896381, Train acc 0.97848, val acc 0.9544, test acc 0.9517, took 6.01 sec.\n",
      "Epoch 44: Train cost 0.0649084076285, Train acc 0.97764, val acc 0.9569, test acc 0.9524, took 5.99 sec.\n",
      "Epoch 45: Train cost 0.0658349692822, Train acc 0.97748, val acc 0.9593, test acc 0.9574, took 6.0 sec.\n",
      "Epoch 46: Train cost 0.0604375228286, Train acc 0.98012, val acc 0.9624, test acc 0.9583, took 6.02 sec.\n",
      "\n",
      "Test 9 is over, saving to history\n",
      "\n",
      "Total time spent: 282.66 seconds\n",
      "Traing Acc: 0.98012\n",
      "Test Acc: 0.9583\n",
      "Validation Acc: 0.9624\n",
      "\n",
      "All Tests All Over\n"
     ]
    }
   ],
   "source": [
    "history = [] # Keep's all the data\n",
    "for ti in range(NUM_TEST):\n",
    "    print \"Creating new model\"\n",
    "    model, l_transform = build_model(DIM, DIM, NUM_CLASSES, MINS, MAXS, RANGES, withdisc=DISC)\n",
    "    model_params = lasagne.layers.get_all_params(model, trainable=True)\n",
    "    # Create Models\n",
    "    X = T.tensor4(dtype=theano.config.floatX)\n",
    "    y = T.ivector()\n",
    "\n",
    "    ## Layer History\n",
    "    if DISC:\n",
    "        l_disc = next(l for l in lasagne.layers.get_all_layers(model) if l.name is 'disclayer')\n",
    "        l_paramreg = next(l for l in lasagne.layers.get_all_layers(model) if l.name is 'param_regressor')\n",
    "        l_disc_output, l_paramreg_output = lasagne.layers.get_output([l_disc, l_paramreg], X, deterministic=False)\n",
    "    ## Layer History\n",
    "\n",
    "    # training output\n",
    "    output_train = lasagne.layers.get_output(model, X, deterministic=False)\n",
    "\n",
    "    # evaluation output. Also includes output of transform for plotting\n",
    "    output_eval, transform_eval = lasagne.layers.get_output([model, l_transform], X, deterministic=True)\n",
    "\n",
    "    sh_lr = theano.shared(lasagne.utils.floatX(LEARNING_RATE))\n",
    "    cost = T.mean(T.nnet.categorical_crossentropy(output_train, y))\n",
    "    #updates = lasagne.updates.sgd(cost, model_params, LEARNING_RATE)\n",
    "    updates = lasagne.updates.adam(cost, model_params, learning_rate=sh_lr)\n",
    "\n",
    "    if DISC:\n",
    "        train = theano.function([X, y], [cost, output_train, l_disc_output, l_paramreg_output], updates=updates)\n",
    "    else:\n",
    "        train = theano.function([X, y], [cost, output_train], updates=updates)\n",
    "    eval = theano.function([X], [output_eval, transform_eval])\n",
    "    # Reset variables\n",
    "    #sh_lr.set_value(lasagne.utils.floatX(LEARNING_RATE)) # Reset Learning rate to origin\n",
    "    valid_accs, train_accs, test_accs = [], [], []\n",
    "    total_time = 0\n",
    "    #param_outputs, disc_outputs = [], []\n",
    "    try:\n",
    "        for n in range(NUM_EPOCHS):\n",
    "            start_time = time.time()\n",
    "            train_cost, train_acc, param_output, disc_output = train_epoch(data['X_train'], data['y_train'])\n",
    "            valid_acc, valid_trainsform = eval_epoch(data['X_valid'], data['y_valid'])\n",
    "            test_acc, test_transform = eval_epoch(data['X_test'], data['y_test'])\n",
    "            valid_accs += [valid_acc]\n",
    "            test_accs += [test_acc]\n",
    "            train_accs += [train_acc]\n",
    "\n",
    "            #if DISC:\n",
    "            #    param_outputs = np.append(param_outputs, param_output)\n",
    "            #    disc_outputs = np.append(disc_outputs, disc_output)\n",
    "            \n",
    "            if (n+1) % 20 == 0:\n",
    "                new_lr = sh_lr.get_value() * 0.7\n",
    "                print \"New LR:\", new_lr\n",
    "                sh_lr.set_value(lasagne.utils.floatX(new_lr))\n",
    "\n",
    "            time_spent = time.time() - start_time\n",
    "            total_time += time_spent\n",
    "            print \"Epoch {0}: Train cost {1}, Train acc {2}, val acc {3}, test acc {4}, took {5:.3} sec.\".format(\n",
    "                    n, train_cost, train_acc, valid_acc, test_acc, time_spent)\n",
    "            \n",
    "            # We'll be stopping the test when we arrive the acc\n",
    "            if train_acc > TH_ACC:\n",
    "                break\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    print \"\\nTest {0} is over, saving to history\".format(ti)\n",
    "    print \"\\nTotal time spent: {0:.5} seconds\\nTraing Acc: {1}\\nTest Acc: {2}\\nValidation Acc: {3}\\n\".format(total_time,\n",
    "                                                                                                             train_acc,\n",
    "                                                                                                             test_acc,\n",
    "                                                                                                             valid_acc)\n",
    "    story = {'train_accs': train_accs,\n",
    "             'test_accs': test_accs,\n",
    "             'valid_accs': valid_accs,\n",
    "             'epoch_reached': n, \n",
    "             'total_time': total_time,\n",
    "             'test_number': (ti+1),\n",
    "             'disc_enabled': DISC,\n",
    "             'learning_rate': LEARNING_RATE,\n",
    "             'batch_size': BATCH_SIZE}\n",
    "    history.append(story)\n",
    "\n",
    "print \"All Tests All Over\"\n",
    "with open(TEST_NAME, 'wb') as fp:\n",
    "  pickle.dump(history, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 43, 40, 43, 42, 40, 42, 45, 41, 46]\n",
      "Trn Accs: [ 0.981  0.982  0.981  0.980  0.981  0.981  0.980  0.982  0.980  0.980], Mean: 0.98093, Std: 0.000680485121072\n",
      "Tst Accs: [ 0.964  0.961  0.962  0.959  0.963  0.962  0.956  0.955  0.958  0.958], Mean: 0.95983, Std: 0.00280536985084\n",
      "Val Accs: [ 0.965  0.962  0.963  0.958  0.962  0.960  0.955  0.956  0.959  0.962], Mean: 0.96016, Std: 0.00298502931309\n"
     ]
    }
   ],
   "source": [
    "with open(TEST_NAME, 'rb') as fp:\n",
    "    history = pickle.load(fp)\n",
    "\n",
    "epochs = [history[i]['epoch_reached'] for i in range(NUM_TEST)]\n",
    "trn_accs = [history[i]['train_accs'][-1] for i in range(NUM_TEST)]\n",
    "tst_accs = [history[i]['test_accs'][-1] for i in range(NUM_TEST)]\n",
    "val_accs = [history[i]['valid_accs'][-1] for i in range(NUM_TEST)]\n",
    "\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "print epochs\n",
    "print \"Trn Accs: {0}, Mean: {1}, Std: {2}\".format(np.asarray(trn_accs), np.mean(trn_accs), np.std(trn_accs))\n",
    "print \"Tst Accs: {0}, Mean: {1}, Std: {2}\".format(np.asarray(tst_accs), np.mean(tst_accs), np.std(tst_accs))\n",
    "print \"Val Accs: {0}, Mean: {1}, Std: {2}\".format(np.asarray(val_accs), np.mean(val_accs), np.std(val_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAHCCAYAAABi0fn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2f28e19d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(1-np.array(train_accs), label='Training Error')\n",
    "plt.plot(1-np.array(valid_accs), label='Validation Error')\n",
    "plt.legend(fontsize=20)\n",
    "plt.xlabel('Epoch', fontsize=8)\n",
    "plt.ylabel('Error', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param_outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-69ed8b1bc679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Histograms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdense_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbin_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplot_over\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'param_outputs' is not defined"
     ]
    }
   ],
   "source": [
    "# Histograms\n",
    "dense_params = param_outputs.reshape((-1, 6))\n",
    "bin_count = 1000\n",
    "plot_over = False\n",
    "\n",
    "for i in range(0, 6):\n",
    "    dns = dense_params[:, i]\n",
    "    \n",
    "    #PS: Using normed histograms to plot them over\n",
    "    # Theta x Dense\n",
    "    plt.figure()\n",
    "    n, bins, patches = plt.hist(dns, bin_count, normed=plot_over, histtype='stepfilled')\n",
    "    plt.setp(patches, 'facecolor', 'r', 'alpha', 0.55)\n",
    "    if not plot_over:\n",
    "        plt.xlabel(('Theta({0}) - Discrete Output').format(i+1))\n",
    "        plt.ylabel('Frequency (Consider bin size)')\n",
    "        plt.grid(True)\n",
    "        plt.figure()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
