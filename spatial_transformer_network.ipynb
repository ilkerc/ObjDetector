{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilker/anaconda/envs/theano/lib/python2.7/site-packages/numpy/lib/utils.py:254: FutureWarning: Numpy has detected that you (may be) writing to an array returned\n",
      "by numpy.diagonal or by selecting multiple fields in a record\n",
      "array. This code will likely break in the next numpy release --\n",
      "see numpy.diagonal or arrays.indexing reference docs for details.\n",
      "The quick fix is to make an explicit copy (e.g., do\n",
      "arr.diagonal().copy() or arr[['f0','f1']].copy()).\n",
      "  ai = a.__array_interface__\n",
      "ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "os.environ['THEANO_FLAGS']='device=gpu0'\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "import matplotlib.pyplot as plt\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from DiscreteLayer import DiscreteLayer\n",
    "conv = lasagne.layers.Conv2DLayer\n",
    "pool = lasagne.layers.MaxPool2DLayer\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "DIM = 60\n",
    "NUM_CLASSES = 10\n",
    "mnist_cluttered = \"mnist_cluttered_60x60_6distortions.npz\"\n",
    "#DISC\n",
    "DISC = True\n",
    "MINS = (-2., -2., -2., -2., -2.,-2.)\n",
    "MAXS = (2., 2., 2., 2., 2.,2.)\n",
    "RANGES = (50, 50, 50, 50, 50, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Spatial Transformer Network\n",
    "We use lasagne to classify cluttered MNIST digits using the spatial transformer network introduced in [1]. The spatial Transformer Network applies a learned affine transformation to its input.\n",
    "\n",
    "\n",
    "\n",
    "## Load data\n",
    "We test the spatial transformer network using cluttered MNIST data.\n",
    "\n",
    "**Download the data (41 mb) with:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!wget -N https://s3.amazonaws.com/lasagne/recipes/datasets/mnist_cluttered_60x60_6distortions.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: (50000, 1, 60, 60)\n",
      "Validation samples: (10000, 1, 60, 60)\n",
      "Test samples: (10000, 1, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    data = np.load(mnist_cluttered)\n",
    "    X_train, y_train = data['x_train'], np.argmax(data['y_train'], axis=-1)\n",
    "    X_valid, y_valid = data['x_valid'], np.argmax(data['y_valid'], axis=-1)\n",
    "    X_test, y_test = data['x_test'], np.argmax(data['y_test'], axis=-1)\n",
    "\n",
    "    # reshape for convolutions\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1, DIM, DIM))\n",
    "    X_valid = X_valid.reshape((X_valid.shape[0], 1, DIM, DIM))\n",
    "    X_test = X_test.reshape((X_test.shape[0], 1, DIM, DIM))\n",
    "    \n",
    "    print \"Train samples:\", X_train.shape\n",
    "    print \"Validation samples:\", X_valid.shape\n",
    "    print \"Test samples:\", X_test.shape\n",
    "\n",
    "    return dict(\n",
    "        X_train=lasagne.utils.floatX(X_train),\n",
    "        y_train=y_train.astype('int32'),\n",
    "        X_valid=lasagne.utils.floatX(X_valid),\n",
    "        y_valid=y_valid.astype('int32'),\n",
    "        X_test=lasagne.utils.floatX(X_test),\n",
    "        y_test=y_test.astype('int32'),\n",
    "        num_examples_train=X_train.shape[0],\n",
    "        num_examples_valid=X_valid.shape[0],\n",
    "        num_examples_test=X_test.shape[0],\n",
    "        input_height=X_train.shape[2],\n",
    "        input_width=X_train.shape[3],\n",
    "        output_dim=10,)\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaUAAAG2CAYAAADfkJmbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\np284zMoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103c1b110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(data['X_train'][2].reshape(DIM, DIM), cmap='gray', interpolation='none')\n",
    "plt.title('Cluttered MNIST', fontsize=20)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model\n",
    "We use a model where the localization network is a two layer convolution network which operates directly on the image input. The output from the localization network is a 6 dimensional vector specifying the parameters in the affine transformation. \n",
    "\n",
    "The localization feeds into the transformer layer which applies the transformation to the image input. In our setup the transformer layer downsamples the input by a factor 3. \n",
    "\n",
    "Finally a 2 layer convolution layer and 2 fully connected layers calculates the output probabilities. \n",
    "\n",
    "**The model**\n",
    "\n",
    "\n",
    "    Input -> localization_network -> TransformerLayer -> output_network -> predictions\n",
    "       |                                |\n",
    "       >--------------------------------^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Discret. Layer\n",
      "Transformer network output shape:  (None, 1, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_width, input_height, output_dim, mins, maxs, ranges,\n",
    "                batch_size=BATCH_SIZE, withdisc=True):\n",
    "    ini = lasagne.init.HeUniform()\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, input_width, input_height),)\n",
    "\n",
    "    # Localization network\n",
    "    b = np.zeros((2, 3), dtype=theano.config.floatX)\n",
    "    b[0, 0] = 1\n",
    "    b[1, 1] = 1\n",
    "    b = b.flatten()\n",
    "    loc_l1 = pool(l_in, pool_size=(2, 2))\n",
    "    loc_l2 = conv(\n",
    "        loc_l1, num_filters=20, filter_size=(5, 5), W=ini)\n",
    "    loc_l3 = pool(loc_l2, pool_size=(2, 2))\n",
    "    loc_l4 = conv(loc_l3, num_filters=20, filter_size=(5, 5), W=ini)\n",
    "    loc_l5 = lasagne.layers.DenseLayer(\n",
    "        loc_l4, num_units=50, W=lasagne.init.HeUniform('relu'))\n",
    "    loc_out = lasagne.layers.DenseLayer(\n",
    "        loc_l5, num_units=6, b=b, W=lasagne.init.Constant(0.0), \n",
    "        nonlinearity=lasagne.nonlinearities.identity, name='param_regressor')\n",
    "    \n",
    "    if withdisc:\n",
    "        l_dis = DiscreteLayer(loc_out, mins, maxs, ranges, name='disclayer')\n",
    "        print(\"Using Discret. Layer\")\n",
    "    else:\n",
    "        l_dis = loc_out\n",
    "        Print(\"No Disc. Layer\")\n",
    "    \n",
    "    # Transformer network\n",
    "    l_trans1 = lasagne.layers.TransformerLayer(l_in, l_dis, downsample_factor=3.0)\n",
    "    print \"Transformer network output shape: \", l_trans1.output_shape\n",
    "    \n",
    "    # Classification network\n",
    "    class_l1 = conv(\n",
    "        l_trans1,\n",
    "        num_filters=32,\n",
    "        filter_size=(3, 3),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )\n",
    "    class_l2 = pool(class_l1, pool_size=(2, 2))\n",
    "    class_l3 = conv(\n",
    "        class_l2,\n",
    "        num_filters=32,\n",
    "        filter_size=(3, 3),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )\n",
    "    class_l4 = pool(class_l3, pool_size=(2, 2))\n",
    "    class_l5 = lasagne.layers.DenseLayer(\n",
    "        class_l4,\n",
    "        num_units=256,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )\n",
    "\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "        class_l5,\n",
    "        num_units=output_dim,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax,\n",
    "        W=ini,\n",
    "    )\n",
    "\n",
    "    return l_out, l_trans1\n",
    "\n",
    "model, l_transform = build_model(DIM, DIM, NUM_CLASSES, MINS, MAXS, RANGES, withdisc=DISC)\n",
    "model_params = lasagne.layers.get_all_params(model, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.gof.compilelock): Overriding existing lock by dead process '44396' (I am process '44980')\n"
     ]
    }
   ],
   "source": [
    "X = T.tensor4()\n",
    "y = T.ivector()\n",
    "\n",
    "## Layer History\n",
    "l_disc = next(l for l in lasagne.layers.get_all_layers(model) if l.name is 'disclayer')\n",
    "l_paramreg = next(l for l in lasagne.layers.get_all_layers(model) if l.name is 'param_regressor')\n",
    "\n",
    "l_disc_output, l_paramreg_output = lasagne.layers.get_output([l_disc, l_paramreg], X, deterministic=False)\n",
    "## Layer History\n",
    "\n",
    "# training output\n",
    "output_train = lasagne.layers.get_output(model, X, deterministic=False)\n",
    "\n",
    "# evaluation output. Also includes output of transform for plotting\n",
    "output_eval, transform_eval = lasagne.layers.get_output([model, l_transform], X, deterministic=True)\n",
    "\n",
    "sh_lr = theano.shared(lasagne.utils.floatX(LEARNING_RATE))\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(output_train, y))\n",
    "updates = lasagne.updates.adam(cost, model_params, learning_rate=sh_lr)\n",
    "\n",
    "train = theano.function([X, y], [cost, output_train, l_disc_output, l_paramreg_output], updates=updates)\n",
    "eval = theano.function([X], [output_eval, transform_eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_epoch(X, y):\n",
    "    # History Keeping\n",
    "    param_output = []\n",
    "    disc_output = []\n",
    "    # History\n",
    "    num_samples = X.shape[0]\n",
    "    num_batches = int(np.ceil(num_samples / float(BATCH_SIZE)))\n",
    "    costs = []\n",
    "    correct = 0\n",
    "    for i in range(num_batches):\n",
    "        idx = range(i*BATCH_SIZE, np.minimum((i+1)*BATCH_SIZE, num_samples))\n",
    "        X_batch = X[idx]\n",
    "        y_batch = y[idx]\n",
    "        cost_batch, output_train, l_disc_output, l_paramreg_output = train(X_batch, y_batch)\n",
    "        param_output = np.append(param_output, l_paramreg_output)\n",
    "        disc_output = np.append(disc_output, l_disc_output)\n",
    "        costs += [cost_batch]\n",
    "        preds = np.argmax(output_train, axis=-1)\n",
    "        correct += np.sum(y_batch == preds)\n",
    "        \n",
    "    return np.mean(costs), correct / float(num_samples), param_output, disc_output\n",
    "\n",
    "\n",
    "def eval_epoch(X, y):\n",
    "    output_eval, transform_eval = eval(X)\n",
    "    preds = np.argmax(output_eval, axis=-1)\n",
    "    acc = np.mean(preds == y)\n",
    "    return acc, transform_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data['X_train'][0:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_accs, train_accs, test_accs = [], [], []\n",
    "param_outputs, disc_outputs = [], []\n",
    "try:\n",
    "    for n in range(NUM_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        train_cost, train_acc, param_output, disc_output = train_epoch(data['X_train'], data['y_train'])\n",
    "        valid_acc, valid_trainsform = eval_epoch(data['X_valid'], data['y_valid'])\n",
    "        test_acc, test_transform = eval_epoch(data['X_test'], data['y_test'])\n",
    "        valid_accs += [valid_acc]\n",
    "        test_accs += [test_acc]\n",
    "        train_accs += [train_acc]\n",
    "        #import pdb; pdb.set_trace()\n",
    "        param_outputs = np.append(param_outputs, param_output)\n",
    "        disc_outputs = np.append(disc_outputs, disc_output)\n",
    "        \n",
    "        if (n+1) % 20 == 0:\n",
    "            new_lr = sh_lr.get_value() * 0.7\n",
    "            print \"New LR:\", new_lr\n",
    "            sh_lr.set_value(lasagne.utils.floatX(new_lr))\n",
    "\n",
    "        print \"Epoch {0}: Train cost {1}, Train acc {2}, val acc {3}, test acc {4}, took {5:.3} sec.\".format(\n",
    "                n, train_cost, train_acc, valid_acc, test_acc, time.time() - start_time)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(1-np.array(train_accs), label='Training Error')\n",
    "plt.plot(1-np.array(valid_accs), label='Validation Error')\n",
    "plt.legend(fontsize=20)\n",
    "plt.xlabel('Epoch', fontsize=8)\n",
    "plt.ylabel('Error', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reshape\n",
    "dense_params = param_outputs.reshape((-1, 6))\n",
    "disc_params = disc_outputs.reshape((-1, 6))\n",
    "print dense_params.shape\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dense_params[::100, 1], 'o')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dense_params[::100, 3], 'o')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(disc_params[::100, 1], 'o')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(disc_params[::100, 3], 'o')\n",
    "plt.grid(True)\n",
    "\n",
    "\"\"\"\n",
    "plt.figure()\n",
    "plt.plot(disc_params[0, 199000:200000:10], '.')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dense_params[1, 0:300000:100], '.')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(disc_params[1, 0:300000:100], '.')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(7,14))\n",
    "for i in range(3):\n",
    "    plt.subplot(321+i*2)\n",
    "    plt.imshow(data['X_test'][i].reshape(DIM, DIM), cmap='gray', interpolation='none')\n",
    "    if i == 0:\n",
    "        plt.title('Original 60x60', fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(322+i*2)\n",
    "    plt.imshow(test_transform[i].reshape(DIM//3, DIM//3), cmap='gray', interpolation='none')\n",
    "    if i == 0:\n",
    "        plt.title('Transformed 20x20', fontsize=20)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# References\n",
    "[1] Jaderberg, Max, et al. \"Spatial Transformer Networks.\" arXiv preprint arXiv:1506.02025 (2015).\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
