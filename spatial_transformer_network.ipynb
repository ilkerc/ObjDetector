{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K40c (CNMeM is enabled with initial size: 69.0% of memory, cuDNN 5105)\n",
      "/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:601: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "os.environ['THEANO_FLAGS']='device=gpu0'\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "import matplotlib.pyplot as plt\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from DiscreteLayer import DiscreteLayer\n",
    "conv = lasagne.layers.Conv2DLayer\n",
    "pool = lasagne.layers.MaxPool2DLayer\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "DIM = 60\n",
    "NUM_CLASSES = 10\n",
    "mnist_cluttered = \"mnist_cluttered_60x60_6distortions.npz\"\n",
    "#DISC\n",
    "DISC = True\n",
    "MINS = (.3, -.3, -.8, .5, -0.7)\n",
    "MAXS = (1.1, .1, 1.1, .4, 1.1, 1.5)\n",
    "RANGES = (50, 50, 50, 50, 50, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Spatial Transformer Network\n",
    "We use lasagne to classify cluttered MNIST digits using the spatial transformer network introduced in [1]. The spatial Transformer Network applies a learned affine transformation to its input.\n",
    "\n",
    "\n",
    "\n",
    "## Load data\n",
    "We test the spatial transformer network using cluttered MNIST data.\n",
    "\n",
    "**Download the data (41 mb) with:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!wget -N https://s3.amazonaws.com/lasagne/recipes/datasets/mnist_cluttered_60x60_6distortions.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: (50000, 1, 60, 60)\n",
      "Validation samples: (10000, 1, 60, 60)\n",
      "Test samples: (10000, 1, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    data = np.load(mnist_cluttered)\n",
    "    X_train, y_train = data['x_train'], np.argmax(data['y_train'], axis=-1)\n",
    "    X_valid, y_valid = data['x_valid'], np.argmax(data['y_valid'], axis=-1)\n",
    "    X_test, y_test = data['x_test'], np.argmax(data['y_test'], axis=-1)\n",
    "\n",
    "    # reshape for convolutions\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1, DIM, DIM))\n",
    "    X_valid = X_valid.reshape((X_valid.shape[0], 1, DIM, DIM))\n",
    "    X_test = X_test.reshape((X_test.shape[0], 1, DIM, DIM))\n",
    "    \n",
    "    print \"Train samples:\", X_train.shape\n",
    "    print \"Validation samples:\", X_valid.shape\n",
    "    print \"Test samples:\", X_test.shape\n",
    "\n",
    "    return dict(\n",
    "        X_train=lasagne.utils.floatX(X_train),\n",
    "        y_train=y_train.astype('int32'),\n",
    "        X_valid=lasagne.utils.floatX(X_valid),\n",
    "        y_valid=y_valid.astype('int32'),\n",
    "        X_test=lasagne.utils.floatX(X_test),\n",
    "        y_test=y_test.astype('int32'),\n",
    "        num_examples_train=X_train.shape[0],\n",
    "        num_examples_valid=X_valid.shape[0],\n",
    "        num_examples_test=X_test.shape[0],\n",
    "        input_height=X_train.shape[2],\n",
    "        input_width=X_train.shape[3],\n",
    "        output_dim=10,)\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAJjCAYAAAAYt4VkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ3PnOrJPyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efdddeeef50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(data['X_train'][2].reshape(DIM, DIM), cmap='gray', interpolation='none')\n",
    "plt.title('Cluttered MNIST', fontsize=20)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model\n",
    "We use a model where the localization network is a two layer convolution network which operates directly on the image input. The output from the localization network is a 6 dimensional vector specifying the parameters in the affine transformation. \n",
    "\n",
    "The localization feeds into the transformer layer which applies the transformation to the image input. In our setup the transformer layer downsamples the input by a factor 3. \n",
    "\n",
    "Finally a 2 layer convolution layer and 2 fully connected layers calculates the output probabilities. \n",
    "\n",
    "**The model**\n",
    "\n",
    "\n",
    "    Input -> localization_network -> TransformerLayer -> output_network -> predictions\n",
    "       |                                |\n",
    "       >--------------------------------^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Discret. Layer\n",
      "Transformer network output shape:  (None, 1, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_width, input_height, output_dim, mins, maxs, ranges,\n",
    "                batch_size=BATCH_SIZE, withdisc=True):\n",
    "    ini = lasagne.init.HeUniform()\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, input_width, input_height),)\n",
    "\n",
    "    # Localization network\n",
    "    b = np.zeros((2, 3), dtype=theano.config.floatX)\n",
    "    b[0, 0] = 1\n",
    "    b[1, 1] = 1\n",
    "    b = b.flatten()\n",
    "    loc_l1 = pool(l_in, pool_size=(2, 2))\n",
    "    loc_l2 = conv(\n",
    "        loc_l1, num_filters=20, filter_size=(5, 5), W=ini)\n",
    "    loc_l3 = pool(loc_l2, pool_size=(2, 2))\n",
    "    loc_l4 = conv(loc_l3, num_filters=20, filter_size=(5, 5), W=ini)\n",
    "    loc_l5 = lasagne.layers.DenseLayer(\n",
    "        loc_l4, num_units=50, W=lasagne.init.HeUniform('relu'))\n",
    "    loc_out = lasagne.layers.DenseLayer(\n",
    "        loc_l5, num_units=6, b=b, W=lasagne.init.Constant(0.0), \n",
    "        nonlinearity=lasagne.nonlinearities.identity, name='param_regressor')\n",
    "    \n",
    "    if withdisc:\n",
    "        l_dis = DiscreteLayer(loc_out, mins, maxs, ranges, name='disclayer')\n",
    "        print(\"Using Discret. Layer\")\n",
    "    else:\n",
    "        l_dis = loc_out\n",
    "        Print(\"No Disc. Layer\")\n",
    "    \n",
    "    # Transformer network\n",
    "    l_trans1 = lasagne.layers.TransformerLayer(l_in, l_dis, downsample_factor=3.0)\n",
    "    print \"Transformer network output shape: \", l_trans1.output_shape\n",
    "    \n",
    "    # Classification network\n",
    "    class_l1 = conv(\n",
    "        l_trans1,\n",
    "        num_filters=32,\n",
    "        filter_size=(3, 3),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )\n",
    "    class_l2 = pool(class_l1, pool_size=(2, 2))\n",
    "    class_l3 = conv(\n",
    "        class_l2,\n",
    "        num_filters=32,\n",
    "        filter_size=(3, 3),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )\n",
    "    class_l4 = pool(class_l3, pool_size=(2, 2))\n",
    "    class_l5 = lasagne.layers.DenseLayer(\n",
    "        class_l4,\n",
    "        num_units=256,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )\n",
    "\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "        class_l5,\n",
    "        num_units=output_dim,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax,\n",
    "        W=ini,\n",
    "    )\n",
    "\n",
    "    return l_out, l_trans1\n",
    "\n",
    "model, l_transform = build_model(DIM, DIM, NUM_CLASSES, MINS, MAXS, RANGES, withdisc=DISC)\n",
    "model_params = lasagne.layers.get_all_params(model, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.tensor4(dtype=theano.config.floatX)\n",
    "y = T.ivector()\n",
    "\n",
    "## Layer History\n",
    "l_disc = next(l for l in lasagne.layers.get_all_layers(model) if l.name is 'disclayer')\n",
    "l_paramreg = next(l for l in lasagne.layers.get_all_layers(model) if l.name is 'param_regressor')\n",
    "\n",
    "l_disc_output, l_paramreg_output = lasagne.layers.get_output([l_disc, l_paramreg], X, deterministic=False)\n",
    "## Layer History\n",
    "\n",
    "# training output\n",
    "output_train = lasagne.layers.get_output(model, X, deterministic=False)\n",
    "\n",
    "# evaluation output. Also includes output of transform for plotting\n",
    "output_eval, transform_eval = lasagne.layers.get_output([model, l_transform], X, deterministic=True)\n",
    "\n",
    "sh_lr = theano.shared(lasagne.utils.floatX(LEARNING_RATE))\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(output_train, y))\n",
    "updates = lasagne.updates.adam(cost, model_params, learning_rate=sh_lr)\n",
    "\n",
    "train = theano.function([X, y], [cost, output_train, l_disc_output, l_paramreg_output], updates=updates)\n",
    "eval = theano.function([X], [output_eval, transform_eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_epoch(X, y):\n",
    "    # History Keeping\n",
    "    param_output = []\n",
    "    disc_output = []\n",
    "    # History\n",
    "    num_samples = X.shape[0]\n",
    "    num_batches = int(np.ceil(num_samples / float(BATCH_SIZE)))\n",
    "    costs = []\n",
    "    correct = 0\n",
    "    for i in range(num_batches):\n",
    "        idx = range(i*BATCH_SIZE, np.minimum((i+1)*BATCH_SIZE, num_samples))\n",
    "        X_batch = X[idx]\n",
    "        y_batch = y[idx]\n",
    "        cost_batch, output_train, l_disc_output, l_paramreg_output = train(X_batch, y_batch)\n",
    "        param_output = np.append(param_output, l_paramreg_output)\n",
    "        disc_output = np.append(disc_output, l_disc_output)\n",
    "        costs += [cost_batch]\n",
    "        preds = np.argmax(output_train, axis=-1)\n",
    "        correct += np.sum(y_batch == preds)\n",
    "        \n",
    "    return np.mean(costs), correct / float(num_samples), param_output, disc_output\n",
    "\n",
    "\n",
    "def eval_epoch(X, y):\n",
    "    output_eval, transform_eval = eval(X)\n",
    "    preds = np.argmax(output_eval, axis=-1)\n",
    "    acc = np.mean(preds == y)\n",
    "    return acc, transform_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "print data['X_train'][0:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range\nApply node that caused the error: DiscOP{mins=(0.3, -0.3, -0.8, 0.5, -0.7), maxs=(1.1, 0.1, 1.1, 0.4, 1.1, 1.5), ranges=(50, 50, 50, 50, 50, 50)}(HostFromGpu.0)\nToposort index: 151\nInputs types: [TensorType(float32, matrix)]\nInputs shapes: [(256, 6)]\nInputs strides: [(24, 4)]\nInputs values: ['not shown']\nInputs type_num: [11]\nOutputs clients: [[Reshape{2}(DiscOP{mins=(0.3, -0.3, -0.8, 0.5, -0.7), maxs=(1.1, 0.1, 1.1, 0.4, 1.1, 1.5), ranges=(50, 50, 50, 50, 50, 50)}.0, MakeVector{dtype='int64'}.0), Shape_i{0}(DiscOP{mins=(0.3, -0.3, -0.8, 0.5, -0.7), maxs=(1.1, 0.1, 1.1, 0.4, 1.1, 1.5), ranges=(50, 50, 50, 50, 50, 50)}.0), Shape_i{1}(DiscOP{mins=(0.3, -0.3, -0.8, 0.5, -0.7), maxs=(1.1, 0.1, 1.1, 0.4, 1.1, 1.5), ranges=(50, 50, 50, 50, 50, 50)}.0), 'output']]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-a3cf72fa4d3e>\", line 8, in <module>\n    l_disc_output, l_paramreg_output = lasagne.layers.get_output([l_disc, l_paramreg], X, deterministic=False)\n  File \"/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/lasagne/layers/helper.py\", line 191, in get_output\n    all_outputs[layer] = layer.get_output_for(layer_inputs, **kwargs)\n  File \"DiscreteLayer.py\", line 13, in get_output_for\n    return self.op(theta)\n\nDebugprint of the apply node: \nDiscOP{mins=(0.3, -0.3, -0.8, 0.5, -0.7), maxs=(1.1, 0.1, 1.1, 0.4, 1.1, 1.5), ranges=(50, 50, 50, 50, 50, 50)} [id A] <TensorType(float32, matrix)> ''   \n |HostFromGpu [id B] <TensorType(float32, matrix)> ''   \n   |GpuElemwise{Add}[(0, 0)] [id C] <CudaNdarrayType(float32, matrix)> ''   \n     |GpuDot22 [id D] <CudaNdarrayType(float32, matrix)> ''   \n     | |GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace} [id E] <CudaNdarrayType(float32, matrix)> ''   \n     | | |CudaNdarrayConstant{[[ 0.5]]} [id F] <CudaNdarrayType(float32, (True, True))>\n     | | |GpuElemwise{Add}[(0, 0)] [id G] <CudaNdarrayType(float32, matrix)> ''   \n     | |   |GpuDot22 [id H] <CudaNdarrayType(float32, matrix)> ''   \n     | |   | |GpuReshape{2} [id I] <CudaNdarrayType(float32, matrix)> ''   \n     | |   | | |GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace} [id J] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | | |CudaNdarrayConstant{[[[[ 0.5]]]]} [id K] <CudaNdarrayType(float32, (True, True, True, True))>\n     | |   | | | |GpuElemwise{Add}[(0, 0)] [id L] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   |GpuDnnConv{algo='small', inplace=True} [id M] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |GpuContiguous [id N] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | | |GpuDnnPool{mode='max'} [id O] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |GpuContiguous [id P] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   | |GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace} [id Q] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |   |CudaNdarrayConstant{[[[[ 0.5]]]]} [id K] <CudaNdarrayType(float32, (True, True, True, True))>\n     | |   | | |   | |   |   |GpuElemwise{Add}[(0, 0)] [id R] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |     |GpuDnnConv{algo='small', inplace=True} [id S] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |     | |GpuContiguous [id T] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |     | | |GpuDnnPool{mode='max'} [id U] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |     | |   |GpuContiguous [id V] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |     | |   | |GpuFromHost [id W] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |     | |   |   |<TensorType(float32, 4D)> [id X] <TensorType(float32, 4D)>\n     | |   | | |   | |   |     | |   |TensorConstant{(2,) of 2} [id Y] <TensorType(int64, vector)>\n     | |   | | |   | |   |     | |   |TensorConstant{(2,) of 2} [id Y] <TensorType(int64, vector)>\n     | |   | | |   | |   |     | |   |TensorConstant{(2,) of 0} [id Z] <TensorType(int64, vector)>\n     | |   | | |   | |   |     | |GpuContiguous [id BA] <CudaNdarrayType(float32, (False, True, False, False))> ''   \n     | |   | | |   | |   |     | | |W [id BB] <CudaNdarrayType(float32, (False, True, False, False))>\n     | |   | | |   | |   |     | |GpuAllocEmpty [id BC] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |     | | |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | |<TensorType(float32, 4D)> [id X] <TensorType(float32, 4D)>\n     | |   | | |   | |   |     | | |Shape_i{0} [id BE] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | |W [id BB] <CudaNdarrayType(float32, (False, True, False, False))>\n     | |   | | |   | |   |     | | |Elemwise{Composite{((i0 - (((i1 - i2) * i3) + i2)) + i2)}}[(0, 0)] [id BF] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | |Elemwise{int_div,no_inplace} [id BG] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | | |Shape_i{2} [id BH] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | | | |<TensorType(float32, 4D)> [id X] <TensorType(float32, 4D)>\n     | |   | | |   | |   |     | | | | |TensorConstant{2} [id BI] <TensorType(int8, scalar)>\n     | |   | | |   | |   |     | | | |Shape_i{2} [id BJ] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | | |W [id BB] <CudaNdarrayType(float32, (False, True, False, False))>\n     | |   | | |   | |   |     | | | |TensorConstant{1} [id BK] <TensorType(int8, scalar)>\n     | |   | | |   | |   |     | | | |TensorConstant{1} [id BL] <TensorType(int64, scalar)>\n     | |   | | |   | |   |     | | |Elemwise{Composite{((i0 - (((i1 - i2) * i3) + i2)) + i2)}}[(0, 0)] [id BM] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | |   |Elemwise{int_div,no_inplace} [id BN] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | |   | |Shape_i{3} [id BO] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | |   | | |<TensorType(float32, 4D)> [id X] <TensorType(float32, 4D)>\n     | |   | | |   | |   |     | |   | |TensorConstant{2} [id BI] <TensorType(int8, scalar)>\n     | |   | | |   | |   |     | |   |Shape_i{3} [id BP] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | |   | |W [id BB] <CudaNdarrayType(float32, (False, True, False, False))>\n     | |   | | |   | |   |     | |   |TensorConstant{1} [id BK] <TensorType(int8, scalar)>\n     | |   | | |   | |   |     | |   |TensorConstant{1} [id BL] <TensorType(int64, scalar)>\n     | |   | | |   | |   |     | |GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'} [id BQ] <CDataType{cudnnConvolutionDescriptor_t}> ''   \n     | |   | | |   | |   |     | | |MakeVector{dtype='int64'} [id BR] <TensorType(int64, vector)> ''   \n     | |   | | |   | |   |     | | | |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | |Shape_i{1} [id BS] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | | |<TensorType(float32, 4D)> [id X] <TensorType(float32, 4D)>\n     | |   | | |   | |   |     | | | |Elemwise{int_div,no_inplace} [id BG] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | |Elemwise{int_div,no_inplace} [id BN] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | |MakeVector{dtype='int64'} [id BT] <TensorType(int64, vector)> ''   \n     | |   | | |   | |   |     | |   |Shape_i{0} [id BE] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | |   |TensorConstant{1} [id BL] <TensorType(int64, scalar)>\n     | |   | | |   | |   |     | |   |Shape_i{2} [id BJ] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | |   |Shape_i{3} [id BP] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | |Constant{1.0} [id BU] <float32>\n     | |   | | |   | |   |     | |Constant{0.0} [id BV] <float32>\n     | |   | | |   | |   |     |GpuDimShuffle{x,0,x,x} [id BW] <CudaNdarrayType(float32, (True, False, True, True))> ''   \n     | |   | | |   | |   |       |b [id BX] <CudaNdarrayType(float32, vector)>\n     | |   | | |   | |   |TensorConstant{(2,) of 2} [id Y] <TensorType(int64, vector)>\n     | |   | | |   | |   |TensorConstant{(2,) of 2} [id Y] <TensorType(int64, vector)>\n     | |   | | |   | |   |TensorConstant{(2,) of 0} [id Z] <TensorType(int64, vector)>\n     | |   | | |   | |GpuContiguous [id BY] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | | |W [id BZ] <CudaNdarrayType(float32, 4D)>\n     | |   | | |   | |GpuAllocEmpty [id CA] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | | |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n     | |   | | |   | | |Shape_i{0} [id CB] <TensorType(int64, scalar)> ''   \n     | |   | | |   | | | |W [id BZ] <CudaNdarrayType(float32, 4D)>\n     | |   | | |   | | |Elemwise{Composite{((i0 - (((i1 - i2) * i3) + i2)) + i2)}} [id CC] <TensorType(int64, scalar)> ''   \n     | |   | | |   | | | |TensorConstant{13} [id CD] <TensorType(int64, scalar)>\n     | |   | | |   | | | |Shape_i{2} [id CE] <TensorType(int64, scalar)> ''   \n     | |   | | |   | | | | |W [id BZ] <CudaNdarrayType(float32, 4D)>\n     | |   | | |   | | | |TensorConstant{1} [id BK] <TensorType(int8, scalar)>\n     | |   | | |   | | | |TensorConstant{1} [id BL] <TensorType(int64, scalar)>\n     | |   | | |   | | |Elemwise{Composite{((i0 - (((i1 - i2) * i3) + i2)) + i2)}} [id CF] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |TensorConstant{13} [id CD] <TensorType(int64, scalar)>\n     | |   | | |   | |   |Shape_i{3} [id CG] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   | |W [id BZ] <CudaNdarrayType(float32, 4D)>\n     | |   | | |   | |   |TensorConstant{1} [id BK] <TensorType(int8, scalar)>\n     | |   | | |   | |   |TensorConstant{1} [id BL] <TensorType(int64, scalar)>\n     | |   | | |   | |GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'} [id CH] <CDataType{cudnnConvolutionDescriptor_t}> ''   \n     | |   | | |   | | |MakeVector{dtype='int64'} [id CI] <TensorType(int64, vector)> ''   \n     | |   | | |   | | | |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n     | |   | | |   | | | |TensorConstant{20} [id CJ] <TensorType(int64, scalar)>\n     | |   | | |   | | | |TensorConstant{13} [id CD] <TensorType(int64, scalar)>\n     | |   | | |   | | | |TensorConstant{13} [id CD] <TensorType(int64, scalar)>\n     | |   | | |   | | |MakeVector{dtype='int64'} [id CK] <TensorType(int64, vector)> ''   \n     | |   | | |   | |   |Shape_i{0} [id CB] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |Shape_i{1} [id CL] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   | |W [id BZ] <CudaNdarrayType(float32, 4D)>\n     | |   | | |   | |   |Shape_i{2} [id CE] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |Shape_i{3} [id CG] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |Constant{1.0} [id BU] <float32>\n     | |   | | |   | |Constant{0.0} [id BV] <float32>\n     | |   | | |   |GpuDimShuffle{x,0,x,x} [id CM] <CudaNdarrayType(float32, (True, False, True, True))> ''   \n     | |   | | |     |b [id CN] <CudaNdarrayType(float32, vector)>\n     | |   | | |MakeVector{dtype='int64'} [id CO] <TensorType(int64, vector)> ''   \n     | |   | |   |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n     | |   | |   |TensorConstant{-1} [id CP] <TensorType(int64, scalar)>\n     | |   | |W [id CQ] <CudaNdarrayType(float32, matrix)>\n     | |   |GpuDimShuffle{x,0} [id CR] <CudaNdarrayType(float32, row)> ''   \n     | |     |b [id CS] <CudaNdarrayType(float32, vector)>\n     | |param_regressor.W [id CT] <CudaNdarrayType(float32, matrix)>\n     |GpuDimShuffle{x,0} [id CU] <CudaNdarrayType(float32, row)> ''   \n       |param_regressor.b [id CV] <CudaNdarrayType(float32, vector)>\n\nStorage map footprint:\n - GpuContiguous.0, Shape: (256, 20, 26, 26), ElemSize: 4 Byte(s), TotalSize: 13844480 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (256, 20, 26, 26), ElemSize: 4 Byte(s), TotalSize: 13844480 Byte(s)\n - <TensorType(float32, 4D)>, Input, Shape: (256, 1, 60, 60), ElemSize: 4 Byte(s), TotalSize: 3686400 Byte(s)\n - GpuFromHost.0, Shape: (256, 1, 60, 60), ElemSize: 4 Byte(s), TotalSize: 3686400 Byte(s)\n - GpuContiguous.0, Shape: (256, 20, 13, 13), ElemSize: 4 Byte(s), TotalSize: 3461120 Byte(s)\n - GpuReshape{2}.0, Shape: (256, 1620), ElemSize: 4 Byte(s), TotalSize: 1658880 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (256, 20, 9, 9), ElemSize: 4 Byte(s), TotalSize: 1658880 Byte(s)\n - GpuContiguous.0, Shape: (256, 1, 30, 30), ElemSize: 4 Byte(s), TotalSize: 921600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1620, 50), ElemSize: 4 Byte(s), TotalSize: 324000 Byte(s)\n - W, Shared Input, Shape: (1620, 50), ElemSize: 4 Byte(s), TotalSize: 324000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1620, 50), ElemSize: 4 Byte(s), TotalSize: 324000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (288, 256), ElemSize: 4 Byte(s), TotalSize: 294912 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (288, 256), ElemSize: 4 Byte(s), TotalSize: 294912 Byte(s)\n - W, Shared Input, Shape: (288, 256), ElemSize: 4 Byte(s), TotalSize: 294912 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (256, 50), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)\n - GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}.0, Shape: (256, 50), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)\n - GpuContiguous.0, Shape: (20, 20, 5, 5), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)\n - W, Shared Input, Shape: (20, 20, 5, 5), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (20, 20, 5, 5), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (20, 20, 5, 5), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (32, 32, 3, 3), ElemSize: 4 Byte(s), TotalSize: 36864 Byte(s)\n - W, Shared Input, Shape: (32, 32, 3, 3), ElemSize: 4 Byte(s), TotalSize: 36864 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (32, 32, 3, 3), ElemSize: 4 Byte(s), TotalSize: 36864 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (256, 10), ElemSize: 4 Byte(s), TotalSize: 10240 Byte(s)\n - W, Shared Input, Shape: (256, 10), ElemSize: 4 Byte(s), TotalSize: 10240 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (256, 10), ElemSize: 4 Byte(s), TotalSize: 10240 Byte(s)\n - HostFromGpu.0, Shape: (256, 6), ElemSize: 4 Byte(s), TotalSize: 6144 Byte(s)\n - <CudaNdarrayType(float32, (False, True, False, False))>, Shared Input, Shape: (20, 1, 5, 5), ElemSize: 4 Byte(s), TotalSize: 2000 Byte(s)\n - <CudaNdarrayType(float32, (False, True, False, False))>, Shared Input, Shape: (20, 1, 5, 5), ElemSize: 4 Byte(s), TotalSize: 2000 Byte(s)\n - W, Shared Input, Shape: (20, 1, 5, 5), ElemSize: 4 Byte(s), TotalSize: 2000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (50, 6), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - param_regressor.W, Shared Input, Shape: (50, 6), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (50, 6), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - W, Shared Input, Shape: (32, 1, 3, 3), ElemSize: 4 Byte(s), TotalSize: 1152 Byte(s)\n - <CudaNdarrayType(float32, (False, True, False, False))>, Shared Input, Shape: (32, 1, 3, 3), ElemSize: 4 Byte(s), TotalSize: 1152 Byte(s)\n - <CudaNdarrayType(float32, (False, True, False, False))>, Shared Input, Shape: (32, 1, 3, 3), ElemSize: 4 Byte(s), TotalSize: 1152 Byte(s)\n - b, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - <TensorType(int32, vector)>, Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - b, Shared Input, Shape: (50,), ElemSize: 4 Byte(s), TotalSize: 200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (50,), ElemSize: 4 Byte(s), TotalSize: 200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (50,), ElemSize: 4 Byte(s), TotalSize: 200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - b, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - b, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - b, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - b, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - b, Shared Input, Shape: (10,), ElemSize: 4 Byte(s), TotalSize: 40 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (10,), ElemSize: 4 Byte(s), TotalSize: 40 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (10,), ElemSize: 4 Byte(s), TotalSize: 40 Byte(s)\n - TensorConstant{(4,) of 1}, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - param_regressor.b, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)\n - TensorConstant{(2,) of 2}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{[ 1 -1]}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{(2,) of 0}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{6}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{3}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-6}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{0.333333333333}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{13}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{3}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{3}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{32}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1,) of -1}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{4}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{9}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{3}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{20}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-3}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1,) of 2.0}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[[ 0.10000002]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[  9.99999994e-09]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.00099999]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 0.99900001]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[[ 0.5]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 0.00099999]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[[ 0.00099999]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1,) of 0.5}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{0.100000023842}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[[[ 0.99900001]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[[ 0.89999998]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Constant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Constant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[  9.99999994e-09]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.99900001]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 0.10000002]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{0.5}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{0.899999976158}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1,) of 1.0}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.89999998]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.5]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1,) of -1.0}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 0.89999998]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[[  9.99999994e-09]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{0.999000012875}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[ 0.5]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[ 0.]]]}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1, 1) of 1.0}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Constant{0.1}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{(1,) of -1}, Shape: (1,), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{(1,) of 1}, Shape: (1,), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n TotalSize: 45008538.0 Byte(s) 0.042 GB\n TotalSize inputs: 5824002.0 Byte(s) 0.005 GB\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-71b1f1fdbae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_trainsform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5bb775d1820b>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mcost_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_disc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_paramreg_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mparam_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_paramreg_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdisc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_disc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    873\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    876\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilker/bap/ObjDetector/helpers/DiscOP.pyc\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inputs, output_storage)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mnew_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscrete_theta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Output Setting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilker/bap/ObjDetector/helpers/DiscOP.pyc\u001b[0m in \u001b[0;36mdiscrete_theta\u001b[0;34m(self, theta)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mt_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mt_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mt_6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mt_1_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range\nApply node that caused the error: DiscOP{mins=(0.3, -0.3, -0.8, 0.5, -0.7), maxs=(1.1, 0.1, 1.1, 0.4, 1.1, 1.5), ranges=(50, 50, 50, 50, 50, 50)}(HostFromGpu.0)\nToposort index: 151\nInputs types: [TensorType(float32, matrix)]\nInputs shapes: [(256, 6)]\nInputs strides: [(24, 4)]\nInputs values: ['not shown']\nInputs type_num: [11]\nOutputs clients: [[Reshape{2}(DiscOP{mins=(0.3, -0.3, -0.8, 0.5, -0.7), maxs=(1.1, 0.1, 1.1, 0.4, 1.1, 1.5), ranges=(50, 50, 50, 50, 50, 50)}.0, MakeVector{dtype='int64'}.0), Shape_i{0}(DiscOP{mins=(0.3, -0.3, -0.8, 0.5, -0.7), maxs=(1.1, 0.1, 1.1, 0.4, 1.1, 1.5), ranges=(50, 50, 50, 50, 50, 50)}.0), Shape_i{1}(DiscOP{mins=(0.3, -0.3, -0.8, 0.5, -0.7), maxs=(1.1, 0.1, 1.1, 0.4, 1.1, 1.5), ranges=(50, 50, 50, 50, 50, 50)}.0), 'output']]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-a3cf72fa4d3e>\", line 8, in <module>\n    l_disc_output, l_paramreg_output = lasagne.layers.get_output([l_disc, l_paramreg], X, deterministic=False)\n  File \"/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/lasagne/layers/helper.py\", line 191, in get_output\n    all_outputs[layer] = layer.get_output_for(layer_inputs, **kwargs)\n  File \"DiscreteLayer.py\", line 13, in get_output_for\n    return self.op(theta)\n\nDebugprint of the apply node: \nDiscOP{mins=(0.3, -0.3, -0.8, 0.5, -0.7), maxs=(1.1, 0.1, 1.1, 0.4, 1.1, 1.5), ranges=(50, 50, 50, 50, 50, 50)} [id A] <TensorType(float32, matrix)> ''   \n |HostFromGpu [id B] <TensorType(float32, matrix)> ''   \n   |GpuElemwise{Add}[(0, 0)] [id C] <CudaNdarrayType(float32, matrix)> ''   \n     |GpuDot22 [id D] <CudaNdarrayType(float32, matrix)> ''   \n     | |GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace} [id E] <CudaNdarrayType(float32, matrix)> ''   \n     | | |CudaNdarrayConstant{[[ 0.5]]} [id F] <CudaNdarrayType(float32, (True, True))>\n     | | |GpuElemwise{Add}[(0, 0)] [id G] <CudaNdarrayType(float32, matrix)> ''   \n     | |   |GpuDot22 [id H] <CudaNdarrayType(float32, matrix)> ''   \n     | |   | |GpuReshape{2} [id I] <CudaNdarrayType(float32, matrix)> ''   \n     | |   | | |GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace} [id J] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | | |CudaNdarrayConstant{[[[[ 0.5]]]]} [id K] <CudaNdarrayType(float32, (True, True, True, True))>\n     | |   | | | |GpuElemwise{Add}[(0, 0)] [id L] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   |GpuDnnConv{algo='small', inplace=True} [id M] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |GpuContiguous [id N] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | | |GpuDnnPool{mode='max'} [id O] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |GpuContiguous [id P] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   | |GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace} [id Q] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |   |CudaNdarrayConstant{[[[[ 0.5]]]]} [id K] <CudaNdarrayType(float32, (True, True, True, True))>\n     | |   | | |   | |   |   |GpuElemwise{Add}[(0, 0)] [id R] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |     |GpuDnnConv{algo='small', inplace=True} [id S] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |     | |GpuContiguous [id T] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |     | | |GpuDnnPool{mode='max'} [id U] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |     | |   |GpuContiguous [id V] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |     | |   | |GpuFromHost [id W] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |     | |   |   |<TensorType(float32, 4D)> [id X] <TensorType(float32, 4D)>\n     | |   | | |   | |   |     | |   |TensorConstant{(2,) of 2} [id Y] <TensorType(int64, vector)>\n     | |   | | |   | |   |     | |   |TensorConstant{(2,) of 2} [id Y] <TensorType(int64, vector)>\n     | |   | | |   | |   |     | |   |TensorConstant{(2,) of 0} [id Z] <TensorType(int64, vector)>\n     | |   | | |   | |   |     | |GpuContiguous [id BA] <CudaNdarrayType(float32, (False, True, False, False))> ''   \n     | |   | | |   | |   |     | | |W [id BB] <CudaNdarrayType(float32, (False, True, False, False))>\n     | |   | | |   | |   |     | |GpuAllocEmpty [id BC] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | |   |     | | |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | |<TensorType(float32, 4D)> [id X] <TensorType(float32, 4D)>\n     | |   | | |   | |   |     | | |Shape_i{0} [id BE] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | |W [id BB] <CudaNdarrayType(float32, (False, True, False, False))>\n     | |   | | |   | |   |     | | |Elemwise{Composite{((i0 - (((i1 - i2) * i3) + i2)) + i2)}}[(0, 0)] [id BF] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | |Elemwise{int_div,no_inplace} [id BG] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | | |Shape_i{2} [id BH] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | | | |<TensorType(float32, 4D)> [id X] <TensorType(float32, 4D)>\n     | |   | | |   | |   |     | | | | |TensorConstant{2} [id BI] <TensorType(int8, scalar)>\n     | |   | | |   | |   |     | | | |Shape_i{2} [id BJ] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | | |W [id BB] <CudaNdarrayType(float32, (False, True, False, False))>\n     | |   | | |   | |   |     | | | |TensorConstant{1} [id BK] <TensorType(int8, scalar)>\n     | |   | | |   | |   |     | | | |TensorConstant{1} [id BL] <TensorType(int64, scalar)>\n     | |   | | |   | |   |     | | |Elemwise{Composite{((i0 - (((i1 - i2) * i3) + i2)) + i2)}}[(0, 0)] [id BM] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | |   |Elemwise{int_div,no_inplace} [id BN] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | |   | |Shape_i{3} [id BO] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | |   | | |<TensorType(float32, 4D)> [id X] <TensorType(float32, 4D)>\n     | |   | | |   | |   |     | |   | |TensorConstant{2} [id BI] <TensorType(int8, scalar)>\n     | |   | | |   | |   |     | |   |Shape_i{3} [id BP] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | |   | |W [id BB] <CudaNdarrayType(float32, (False, True, False, False))>\n     | |   | | |   | |   |     | |   |TensorConstant{1} [id BK] <TensorType(int8, scalar)>\n     | |   | | |   | |   |     | |   |TensorConstant{1} [id BL] <TensorType(int64, scalar)>\n     | |   | | |   | |   |     | |GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'} [id BQ] <CDataType{cudnnConvolutionDescriptor_t}> ''   \n     | |   | | |   | |   |     | | |MakeVector{dtype='int64'} [id BR] <TensorType(int64, vector)> ''   \n     | |   | | |   | |   |     | | | |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | |Shape_i{1} [id BS] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | | |<TensorType(float32, 4D)> [id X] <TensorType(float32, 4D)>\n     | |   | | |   | |   |     | | | |Elemwise{int_div,no_inplace} [id BG] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | | |Elemwise{int_div,no_inplace} [id BN] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | | |MakeVector{dtype='int64'} [id BT] <TensorType(int64, vector)> ''   \n     | |   | | |   | |   |     | |   |Shape_i{0} [id BE] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | |   |TensorConstant{1} [id BL] <TensorType(int64, scalar)>\n     | |   | | |   | |   |     | |   |Shape_i{2} [id BJ] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | |   |Shape_i{3} [id BP] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |     | |Constant{1.0} [id BU] <float32>\n     | |   | | |   | |   |     | |Constant{0.0} [id BV] <float32>\n     | |   | | |   | |   |     |GpuDimShuffle{x,0,x,x} [id BW] <CudaNdarrayType(float32, (True, False, True, True))> ''   \n     | |   | | |   | |   |       |b [id BX] <CudaNdarrayType(float32, vector)>\n     | |   | | |   | |   |TensorConstant{(2,) of 2} [id Y] <TensorType(int64, vector)>\n     | |   | | |   | |   |TensorConstant{(2,) of 2} [id Y] <TensorType(int64, vector)>\n     | |   | | |   | |   |TensorConstant{(2,) of 0} [id Z] <TensorType(int64, vector)>\n     | |   | | |   | |GpuContiguous [id BY] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | | |W [id BZ] <CudaNdarrayType(float32, 4D)>\n     | |   | | |   | |GpuAllocEmpty [id CA] <CudaNdarrayType(float32, 4D)> ''   \n     | |   | | |   | | |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n     | |   | | |   | | |Shape_i{0} [id CB] <TensorType(int64, scalar)> ''   \n     | |   | | |   | | | |W [id BZ] <CudaNdarrayType(float32, 4D)>\n     | |   | | |   | | |Elemwise{Composite{((i0 - (((i1 - i2) * i3) + i2)) + i2)}} [id CC] <TensorType(int64, scalar)> ''   \n     | |   | | |   | | | |TensorConstant{13} [id CD] <TensorType(int64, scalar)>\n     | |   | | |   | | | |Shape_i{2} [id CE] <TensorType(int64, scalar)> ''   \n     | |   | | |   | | | | |W [id BZ] <CudaNdarrayType(float32, 4D)>\n     | |   | | |   | | | |TensorConstant{1} [id BK] <TensorType(int8, scalar)>\n     | |   | | |   | | | |TensorConstant{1} [id BL] <TensorType(int64, scalar)>\n     | |   | | |   | | |Elemwise{Composite{((i0 - (((i1 - i2) * i3) + i2)) + i2)}} [id CF] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |TensorConstant{13} [id CD] <TensorType(int64, scalar)>\n     | |   | | |   | |   |Shape_i{3} [id CG] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   | |W [id BZ] <CudaNdarrayType(float32, 4D)>\n     | |   | | |   | |   |TensorConstant{1} [id BK] <TensorType(int8, scalar)>\n     | |   | | |   | |   |TensorConstant{1} [id BL] <TensorType(int64, scalar)>\n     | |   | | |   | |GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'} [id CH] <CDataType{cudnnConvolutionDescriptor_t}> ''   \n     | |   | | |   | | |MakeVector{dtype='int64'} [id CI] <TensorType(int64, vector)> ''   \n     | |   | | |   | | | |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n     | |   | | |   | | | |TensorConstant{20} [id CJ] <TensorType(int64, scalar)>\n     | |   | | |   | | | |TensorConstant{13} [id CD] <TensorType(int64, scalar)>\n     | |   | | |   | | | |TensorConstant{13} [id CD] <TensorType(int64, scalar)>\n     | |   | | |   | | |MakeVector{dtype='int64'} [id CK] <TensorType(int64, vector)> ''   \n     | |   | | |   | |   |Shape_i{0} [id CB] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |Shape_i{1} [id CL] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   | |W [id BZ] <CudaNdarrayType(float32, 4D)>\n     | |   | | |   | |   |Shape_i{2} [id CE] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |   |Shape_i{3} [id CG] <TensorType(int64, scalar)> ''   \n     | |   | | |   | |Constant{1.0} [id BU] <float32>\n     | |   | | |   | |Constant{0.0} [id BV] <float32>\n     | |   | | |   |GpuDimShuffle{x,0,x,x} [id CM] <CudaNdarrayType(float32, (True, False, True, True))> ''   \n     | |   | | |     |b [id CN] <CudaNdarrayType(float32, vector)>\n     | |   | | |MakeVector{dtype='int64'} [id CO] <TensorType(int64, vector)> ''   \n     | |   | |   |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n     | |   | |   |TensorConstant{-1} [id CP] <TensorType(int64, scalar)>\n     | |   | |W [id CQ] <CudaNdarrayType(float32, matrix)>\n     | |   |GpuDimShuffle{x,0} [id CR] <CudaNdarrayType(float32, row)> ''   \n     | |     |b [id CS] <CudaNdarrayType(float32, vector)>\n     | |param_regressor.W [id CT] <CudaNdarrayType(float32, matrix)>\n     |GpuDimShuffle{x,0} [id CU] <CudaNdarrayType(float32, row)> ''   \n       |param_regressor.b [id CV] <CudaNdarrayType(float32, vector)>\n\nStorage map footprint:\n - GpuContiguous.0, Shape: (256, 20, 26, 26), ElemSize: 4 Byte(s), TotalSize: 13844480 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (256, 20, 26, 26), ElemSize: 4 Byte(s), TotalSize: 13844480 Byte(s)\n - <TensorType(float32, 4D)>, Input, Shape: (256, 1, 60, 60), ElemSize: 4 Byte(s), TotalSize: 3686400 Byte(s)\n - GpuFromHost.0, Shape: (256, 1, 60, 60), ElemSize: 4 Byte(s), TotalSize: 3686400 Byte(s)\n - GpuContiguous.0, Shape: (256, 20, 13, 13), ElemSize: 4 Byte(s), TotalSize: 3461120 Byte(s)\n - GpuReshape{2}.0, Shape: (256, 1620), ElemSize: 4 Byte(s), TotalSize: 1658880 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (256, 20, 9, 9), ElemSize: 4 Byte(s), TotalSize: 1658880 Byte(s)\n - GpuContiguous.0, Shape: (256, 1, 30, 30), ElemSize: 4 Byte(s), TotalSize: 921600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1620, 50), ElemSize: 4 Byte(s), TotalSize: 324000 Byte(s)\n - W, Shared Input, Shape: (1620, 50), ElemSize: 4 Byte(s), TotalSize: 324000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1620, 50), ElemSize: 4 Byte(s), TotalSize: 324000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (288, 256), ElemSize: 4 Byte(s), TotalSize: 294912 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (288, 256), ElemSize: 4 Byte(s), TotalSize: 294912 Byte(s)\n - W, Shared Input, Shape: (288, 256), ElemSize: 4 Byte(s), TotalSize: 294912 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (256, 50), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)\n - GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}.0, Shape: (256, 50), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)\n - GpuContiguous.0, Shape: (20, 20, 5, 5), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)\n - W, Shared Input, Shape: (20, 20, 5, 5), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (20, 20, 5, 5), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (20, 20, 5, 5), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (32, 32, 3, 3), ElemSize: 4 Byte(s), TotalSize: 36864 Byte(s)\n - W, Shared Input, Shape: (32, 32, 3, 3), ElemSize: 4 Byte(s), TotalSize: 36864 Byte(s)\n - <CudaNdarrayType(float32, 4D)>, Shared Input, Shape: (32, 32, 3, 3), ElemSize: 4 Byte(s), TotalSize: 36864 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (256, 10), ElemSize: 4 Byte(s), TotalSize: 10240 Byte(s)\n - W, Shared Input, Shape: (256, 10), ElemSize: 4 Byte(s), TotalSize: 10240 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (256, 10), ElemSize: 4 Byte(s), TotalSize: 10240 Byte(s)\n - HostFromGpu.0, Shape: (256, 6), ElemSize: 4 Byte(s), TotalSize: 6144 Byte(s)\n - <CudaNdarrayType(float32, (False, True, False, False))>, Shared Input, Shape: (20, 1, 5, 5), ElemSize: 4 Byte(s), TotalSize: 2000 Byte(s)\n - <CudaNdarrayType(float32, (False, True, False, False))>, Shared Input, Shape: (20, 1, 5, 5), ElemSize: 4 Byte(s), TotalSize: 2000 Byte(s)\n - W, Shared Input, Shape: (20, 1, 5, 5), ElemSize: 4 Byte(s), TotalSize: 2000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (50, 6), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - param_regressor.W, Shared Input, Shape: (50, 6), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (50, 6), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - W, Shared Input, Shape: (32, 1, 3, 3), ElemSize: 4 Byte(s), TotalSize: 1152 Byte(s)\n - <CudaNdarrayType(float32, (False, True, False, False))>, Shared Input, Shape: (32, 1, 3, 3), ElemSize: 4 Byte(s), TotalSize: 1152 Byte(s)\n - <CudaNdarrayType(float32, (False, True, False, False))>, Shared Input, Shape: (32, 1, 3, 3), ElemSize: 4 Byte(s), TotalSize: 1152 Byte(s)\n - b, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - <TensorType(int32, vector)>, Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - b, Shared Input, Shape: (50,), ElemSize: 4 Byte(s), TotalSize: 200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (50,), ElemSize: 4 Byte(s), TotalSize: 200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (50,), ElemSize: 4 Byte(s), TotalSize: 200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - b, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - b, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - b, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - b, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - b, Shared Input, Shape: (10,), ElemSize: 4 Byte(s), TotalSize: 40 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (10,), ElemSize: 4 Byte(s), TotalSize: 40 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (10,), ElemSize: 4 Byte(s), TotalSize: 40 Byte(s)\n - TensorConstant{(4,) of 1}, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - param_regressor.b, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)\n - TensorConstant{(2,) of 2}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{[ 1 -1]}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{(2,) of 0}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{6}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{3}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-6}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{0.333333333333}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{13}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{3}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{3}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{32}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1,) of -1}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{4}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{9}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{3}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{20}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-3}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1,) of 2.0}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[[ 0.10000002]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[  9.99999994e-09]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.00099999]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 0.99900001]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[[ 0.5]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 0.00099999]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[[ 0.00099999]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1,) of 0.5}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{0.100000023842}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[[[ 0.99900001]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[[ 0.89999998]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Constant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Constant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[  9.99999994e-09]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.99900001]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 0.10000002]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{0.5}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{0.899999976158}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1,) of 1.0}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.89999998]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.5]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1,) of -1.0}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 0.89999998]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[[  9.99999994e-09]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{0.999000012875}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[ 0.5]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[ 0.]]]}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1, 1) of 1.0}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Constant{0.1}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{(1,) of -1}, Shape: (1,), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{(1,) of 1}, Shape: (1,), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n TotalSize: 45008538.0 Byte(s) 0.042 GB\n TotalSize inputs: 5824002.0 Byte(s) 0.005 GB\n\n"
     ]
    }
   ],
   "source": [
    "theano.config.exception_verbosity = 'high'\n",
    "valid_accs, train_accs, test_accs = [], [], []\n",
    "param_outputs, disc_outputs = [], []\n",
    "try:\n",
    "    for n in range(NUM_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        train_cost, train_acc, param_output, disc_output = train_epoch(data['X_train'], data['y_train'])\n",
    "        valid_acc, valid_trainsform = eval_epoch(data['X_valid'], data['y_valid'])\n",
    "        test_acc, test_transform = eval_epoch(data['X_test'], data['y_test'])\n",
    "        valid_accs += [valid_acc]\n",
    "        test_accs += [test_acc]\n",
    "        train_accs += [train_acc]\n",
    "        #import pdb; pdb.set_trace()\n",
    "        param_outputs = np.append(param_outputs, param_output)\n",
    "        disc_outputs = np.append(disc_outputs, disc_output)\n",
    "        \n",
    "        if (n+1) % 20 == 0:\n",
    "            new_lr = sh_lr.get_value() * 0.7\n",
    "            print \"New LR:\", new_lr\n",
    "            sh_lr.set_value(lasagne.utils.floatX(new_lr))\n",
    "\n",
    "        print \"Epoch {0}: Train cost {1}, Train acc {2}, val acc {3}, test acc {4}, took {5:.3} sec.\".format(\n",
    "                n, train_cost, train_acc, valid_acc, test_acc, time.time() - start_time)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(1-np.array(train_accs), label='Training Error')\n",
    "plt.plot(1-np.array(valid_accs), label='Validation Error')\n",
    "plt.legend(fontsize=20)\n",
    "plt.xlabel('Epoch', fontsize=8)\n",
    "plt.ylabel('Error', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reshape\n",
    "dense_params = param_outputs.reshape((-1, 6))\n",
    "disc_params = disc_outputs.reshape((-1, 6))\n",
    "print dense_params.shape\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dense_params[::100, 0], 'o')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dense_params[::100, 1], 'o')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dense_params[::100, 2], 'o')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dense_params[::100, 3], 'o')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dense_params[::100, 4], 'o')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dense_params[::100, 5], 'o')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(disc_params[::100, 1], 'o')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(disc_params[::100, 3], 'o')\n",
    "plt.grid(True)\n",
    "\n",
    "\"\"\"\n",
    "plt.figure()\n",
    "plt.plot(disc_params[0, 199000:200000:10], '.')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dense_params[1, 0:300000:100], '.')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(disc_params[1, 0:300000:100], '.')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(7,14))\n",
    "for i in range(3):\n",
    "    plt.subplot(321+i*2)\n",
    "    plt.imshow(data['X_test'][i].reshape(DIM, DIM), cmap='gray', interpolation='none')\n",
    "    if i == 0:\n",
    "        plt.title('Original 60x60', fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(322+i*2)\n",
    "    plt.imshow(test_transform[i].reshape(DIM//3, DIM//3), cmap='gray', interpolation='none')\n",
    "    if i == 0:\n",
    "        plt.title('Transformed 20x20', fontsize=20)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# References\n",
    "[1] Jaderberg, Max, et al. \"Spatial Transformer Networks.\" arXiv preprint arXiv:1506.02025 (2015).\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
