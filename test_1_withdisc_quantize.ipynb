{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K40c (CNMeM is enabled with initial size: 33.0% of memory, cuDNN 5105)\n",
      "/home/ilker/anaconda2/envs/theano/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:601: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import matplotlib\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import pylab as P\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle as pickle\n",
    "from DiscreteLayer import DiscreteLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "# theano.config.exception_verbosity = 'high'\n",
    "conv = lasagne.layers.Conv2DLayer\n",
    "pool = lasagne.layers.MaxPool2DLayer\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "DIM = 60\n",
    "NUM_CLASSES = 10\n",
    "mnist_cluttered = \"mnist_cluttered_60x60_6distortions.npz\"\n",
    "#DISC\n",
    "DISC = True\n",
    "MINS = (.3, -.3, -.8, -.3, .5, -0.7)\n",
    "MAXS = (1.1, .1, 1.1, .4, 1.1, 1.5)\n",
    "RANGES = (50, 50, 50, 50, 50, 50)\n",
    "QUANT = np.array([0.008, 0.004, 0.019, 0.007, 0.006, 0.024], dtype='float32')\n",
    "#Test Specs\n",
    "TH_ACC = 0.98\n",
    "NUM_TEST = 10\n",
    "TEST_NAME = 'test1_disc_quantize'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: (50000, 1, 60, 60)\n",
      "Validation samples: (10000, 1, 60, 60)\n",
      "Test samples: (10000, 1, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    data = np.load(mnist_cluttered)\n",
    "    X_train, y_train = data['x_train'], np.argmax(data['y_train'], axis=-1)\n",
    "    X_valid, y_valid = data['x_valid'], np.argmax(data['y_valid'], axis=-1)\n",
    "    X_test, y_test = data['x_test'], np.argmax(data['y_test'], axis=-1)\n",
    "\n",
    "    # reshape for convolutions\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1, DIM, DIM))\n",
    "    X_valid = X_valid.reshape((X_valid.shape[0], 1, DIM, DIM))\n",
    "    X_test = X_test.reshape((X_test.shape[0], 1, DIM, DIM))\n",
    "    \n",
    "    print \"Train samples:\", X_train.shape\n",
    "    print \"Validation samples:\", X_valid.shape\n",
    "    print \"Test samples:\", X_test.shape\n",
    "\n",
    "    return dict(\n",
    "        X_train=lasagne.utils.floatX(X_train),\n",
    "        y_train=y_train.astype('int32'),\n",
    "        X_valid=lasagne.utils.floatX(X_valid),\n",
    "        y_valid=y_valid.astype('int32'),\n",
    "        X_test=lasagne.utils.floatX(X_test),\n",
    "        y_test=y_test.astype('int32'),\n",
    "        num_examples_train=X_train.shape[0],\n",
    "        num_examples_valid=X_valid.shape[0],\n",
    "        num_examples_test=X_test.shape[0],\n",
    "        input_height=X_train.shape[2],\n",
    "        input_width=X_train.shape[3],\n",
    "        output_dim=10,)\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Discret. Layer\n",
      "Transformer network output shape:  (None, 1, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_width, input_height, output_dim, mins, maxs, ranges,\n",
    "                batch_size=BATCH_SIZE, withdisc=True):\n",
    "    ini = lasagne.init.HeUniform()\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, input_width, input_height),)\n",
    "    #l_in = lasagne.layers.DropoutLayer(l_in, p=0.1)\n",
    "\n",
    "    # Localization network\n",
    "    b = np.zeros((2, 3), dtype=theano.config.floatX)\n",
    "    b[0, 0] = 1\n",
    "    b[1, 1] = 1\n",
    "    b = b.flatten()\n",
    "    loc_l1 = pool(l_in, pool_size=(2, 2))\n",
    "    loc_l2 = conv(\n",
    "        loc_l1, num_filters=20, filter_size=(5, 5), W=ini)\n",
    "    loc_l3 = pool(loc_l2, pool_size=(2, 2))\n",
    "    loc_l4 = conv(loc_l3, num_filters=20, filter_size=(5, 5), W=ini)\n",
    "    loc_l5 = lasagne.layers.DenseLayer(\n",
    "        loc_l4, num_units=50, W=lasagne.init.HeUniform('relu'))\n",
    "    loc_out = lasagne.layers.DenseLayer(\n",
    "        loc_l5, num_units=6, b=b, W=lasagne.init.Constant(0.0), \n",
    "        nonlinearity=lasagne.nonlinearities.identity, name='param_regressor')\n",
    "    \n",
    "    if withdisc:\n",
    "        l_dis = DiscreteLayer(loc_out, mins, maxs, ranges, QUANT, name='disclayer')\n",
    "        print(\"Using Discret. Layer\")\n",
    "    else:\n",
    "        l_dis = loc_out\n",
    "        print(\"No Disc. Layer\")\n",
    "    \n",
    "    # Transformer network\n",
    "    l_trans1 = lasagne.layers.TransformerLayer(l_in, l_dis, downsample_factor=3.0)\n",
    "    print \"Transformer network output shape: \", l_trans1.output_shape\n",
    "    \n",
    "    # Classification network\n",
    "    class_l1 = conv(\n",
    "        l_trans1,\n",
    "        num_filters=32,\n",
    "        filter_size=(3, 3),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )\n",
    "    class_l2 = pool(class_l1, pool_size=(2, 2))\n",
    "    class_l3 = conv(\n",
    "        class_l2,\n",
    "        num_filters=32,\n",
    "        filter_size=(3, 3),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )\n",
    "    class_l4 = pool(class_l3, pool_size=(2, 2))\n",
    "    class_l5 = lasagne.layers.DenseLayer(\n",
    "        class_l4,\n",
    "        num_units=256,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )\n",
    "\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "        class_l5,\n",
    "        num_units=output_dim,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax,\n",
    "        W=ini,\n",
    "    )\n",
    "\n",
    "    return l_out, l_trans1\n",
    "\n",
    "model, l_transform = build_model(DIM, DIM, NUM_CLASSES, MINS, MAXS, RANGES, withdisc=DISC)\n",
    "model_params = lasagne.layers.get_all_params(model, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.tensor4(dtype=theano.config.floatX)\n",
    "y = T.ivector()\n",
    "\n",
    "## Layer History\n",
    "if DISC:\n",
    "    l_disc = next(l for l in lasagne.layers.get_all_layers(model) if l.name is 'disclayer')\n",
    "    l_paramreg = next(l for l in lasagne.layers.get_all_layers(model) if l.name is 'param_regressor')\n",
    "    l_disc_output, l_paramreg_output = lasagne.layers.get_output([l_disc, l_paramreg], X, deterministic=False)\n",
    "## Layer History\n",
    "\n",
    "# training output\n",
    "output_train = lasagne.layers.get_output(model, X, deterministic=False)\n",
    "\n",
    "# evaluation output. Also includes output of transform for plotting\n",
    "output_eval, transform_eval = lasagne.layers.get_output([model, l_transform], X, deterministic=True)\n",
    "\n",
    "sh_lr = theano.shared(lasagne.utils.floatX(LEARNING_RATE))\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(output_train, y))\n",
    "#updates = lasagne.updates.sgd(cost, model_params, LEARNING_RATE)\n",
    "updates = lasagne.updates.adam(cost, model_params, learning_rate=sh_lr)\n",
    "\n",
    "if DISC:\n",
    "    train = theano.function([X, y], [cost, output_train, l_disc_output, l_paramreg_output], updates=updates)\n",
    "else:\n",
    "    train = theano.function([X, y], [cost, output_train], updates=updates)\n",
    "eval = theano.function([X], [output_eval, transform_eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(X, y):\n",
    "    # History Keeping\n",
    "    param_output = []\n",
    "    disc_output = []\n",
    "    # History\n",
    "    num_samples = X.shape[0]\n",
    "    num_batches = int(np.ceil(num_samples / float(BATCH_SIZE)))\n",
    "    costs = []\n",
    "    correct = 0\n",
    "    for i in range(num_batches):\n",
    "        idx = range(i*BATCH_SIZE, np.minimum((i+1)*BATCH_SIZE, num_samples))\n",
    "        X_batch = X[idx]\n",
    "        y_batch = y[idx]\n",
    "        if DISC:\n",
    "            cost_batch, output_train, l_disc_output, l_paramreg_output = train(X_batch, y_batch)\n",
    "            param_output = np.append(param_output, l_paramreg_output)\n",
    "            disc_output = np.append(disc_output, l_disc_output)\n",
    "        else:\n",
    "            cost_batch, output_train = train(X_batch, y_batch)\n",
    "        costs += [cost_batch]\n",
    "        preds = np.argmax(output_train, axis=-1)\n",
    "        correct += np.sum(y_batch == preds)\n",
    "        \n",
    "    return np.mean(costs), correct / float(num_samples), param_output, disc_output\n",
    "\n",
    "\n",
    "def eval_epoch(X, y):\n",
    "    output_eval, transform_eval = eval(X)\n",
    "    preds = np.argmax(output_eval, axis=-1)\n",
    "    acc = np.mean(preds == y)\n",
    "    return acc, transform_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train cost 1.93987798691, Train acc 0.30108, val acc 0.4516, test acc 0.4508, took 4.83 sec.\n",
      "Epoch 1: Train cost 1.37571275234, Train acc 0.52646, val acc 0.5417, test acc 0.5406, took 4.82 sec.\n",
      "Epoch 2: Train cost 1.1391992569, Train acc 0.61704, val acc 0.6279, test acc 0.6279, took 4.81 sec.\n",
      "Epoch 3: Train cost 1.00362050533, Train acc 0.66602, val acc 0.6794, test acc 0.6821, took 4.81 sec.\n",
      "Epoch 4: Train cost 0.903560400009, Train acc 0.70298, val acc 0.7039, test acc 0.707, took 4.81 sec.\n",
      "Epoch 5: Train cost 0.827638030052, Train acc 0.72938, val acc 0.7188, test acc 0.7248, took 4.81 sec.\n",
      "Epoch 6: Train cost 0.768962025642, Train acc 0.75082, val acc 0.7282, test acc 0.7345, took 4.81 sec.\n",
      "Epoch 7: Train cost 0.723848462105, Train acc 0.76536, val acc 0.7364, test acc 0.7418, took 4.81 sec.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valid_accs, train_accs, test_accs = [], [], []\n",
    "total_time = 0\n",
    "param_outputs, disc_outputs = [], []\n",
    "try:\n",
    "    for n in range(NUM_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        train_cost, train_acc, param_output, disc_output = train_epoch(data['X_train'], data['y_train'])\n",
    "        valid_acc, valid_trainsform = eval_epoch(data['X_valid'], data['y_valid'])\n",
    "        test_acc, test_transform = eval_epoch(data['X_test'], data['y_test'])\n",
    "        valid_accs += [valid_acc]\n",
    "        test_accs += [test_acc]\n",
    "        train_accs += [train_acc]\n",
    "\n",
    "        if DISC:\n",
    "            param_outputs = np.append(param_outputs, param_output)\n",
    "            disc_outputs = np.append(disc_outputs, disc_output)\n",
    "\n",
    "        if (n+1) % 20 == 0:\n",
    "            new_lr = sh_lr.get_value() * 0.7\n",
    "            print \"New LR:\", new_lr\n",
    "            sh_lr.set_value(lasagne.utils.floatX(new_lr))\n",
    "\n",
    "        time_spent = time.time() - start_time\n",
    "        total_time += time_spent\n",
    "        print \"Epoch {0}: Train cost {1}, Train acc {2}, val acc {3}, test acc {4}, took {5:.3} sec.\".format(\n",
    "                n, train_cost, train_acc, valid_acc, test_acc, time_spent)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "print \"\\nTotal time spent: {0:.5} seconds\\nTraing Acc: {1}\\nTest Acc: {2}\\nValidation Acc: {3}\\n\".format(total_time,\n",
    "                                                                                                         train_acc,\n",
    "                                                                                                         test_acc,\n",
    "                                                                                                         valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(1-np.array(train_accs), label='Training Error')\n",
    "plt.plot(1-np.array(valid_accs), label='Validation Error')\n",
    "plt.legend(fontsize=20)\n",
    "plt.xlabel('Epoch', fontsize=8)\n",
    "plt.ylabel('Error', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense_params = param_outputs.reshape((-1, 6))\n",
    "disc_params = disc_outputs.reshape((-1, 6))\n",
    "print disc_params[100020]\n",
    "print dense_params[100000]\n",
    "\n",
    "model_params[8].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Histograms\n",
    "dense_params = param_outputs.reshape((-1, 6))\n",
    "disc_params = disc_outputs.reshape((-1, 6))\n",
    "\n",
    "bin_count = 100\n",
    "plot_over = False\n",
    "\n",
    "for i in range(0, 6):\n",
    "    dns = dense_params[:, i]\n",
    "    dsc = disc_params[:, i]\n",
    "    \n",
    "    #PS: Using normed histograms to plot them over\n",
    "    # Theta x Dense\n",
    "    plt.figure()\n",
    "    n, bins, patches = plt.hist(dns, bin_count, normed=plot_over, histtype='stepfilled')\n",
    "    plt.setp(patches, 'facecolor', 'r', 'alpha', 0.55)\n",
    "    if not plot_over:\n",
    "        plt.xlabel(('Theta({0}) - Discrete Output').format(i+1))\n",
    "        plt.ylabel('Frequency (Consider bin size)')\n",
    "        plt.grid(True)\n",
    "        plt.figure()\n",
    "    \n",
    "    # Theta x Discrete\n",
    "    n, bins, patches = plt.hist(dsc, len(np.unique(dsc)), normed=plot_over, histtype='stepfilled')\n",
    "    plt.setp(patches, 'facecolor', 'g', 'alpha', 0.55)\n",
    "    if not plot_over:\n",
    "        plt.xlabel(('Theta({0}) - Discrete Output').format(i+1))\n",
    "    else:\n",
    "        plt.xlabel(('Theta({0})').format(i+1))\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,14))\n",
    "for i in range(3):\n",
    "    plt.subplot(321+i*2)\n",
    "    plt.imshow(data['X_test'][i].reshape(DIM, DIM), cmap='gray', interpolation='none')\n",
    "    if i == 0:\n",
    "        plt.title('Original 60x60', fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(322+i*2)\n",
    "    plt.imshow(test_transform[i].reshape(DIM//3, DIM//3), cmap='gray', interpolation='none')\n",
    "    if i == 0:\n",
    "        plt.title('Transformed 20x20', fontsize=20)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:theano]",
   "language": "python",
   "name": "conda-env-theano-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
